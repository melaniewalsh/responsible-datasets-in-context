[
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Library Top 500\n\n\n\n\n\n\nline-plots\n\n\ndata-collection\n\n\nuncertainty\n\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nAnna Preus and Aashna Sheth\n\n\n\n\n\n\n\n\n\n\n\n\nU.S. National Park Visit Data\n\n\n\n\n\n\nline-plots\n\n\ndata-collection\n\n\nuncertainty\n\n\n\n\n\n\n\n\n\nMar 9, 2024\n\n\nMelanie Walsh and Os Keyes\n\n\n\n\n\n\n\n\n\n\n\n\nGender Violence at the Border\n\n\n\n\n\n\nmissing-data\n\n\nuncertainty\n\n\ndata-collection\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nSylvia Fernández and Paulina Hernandez Trejo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/np-data/index.html",
    "href": "posts/np-data/index.html",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Code\n.tabset h2 {display: none;}"
  },
  {
    "objectID": "posts/np-data/index.html#introduction",
    "href": "posts/np-data/index.html#introduction",
    "title": "National Park Visitation Data",
    "section": "Introduction",
    "text": "Introduction\nThis dataset contains the number of visits, per year, to each of the 63 National Parks administered by the United States National Park Service (NPS), from 1979 to the present. The NPS also collects visitation data for other park units, such as national battlfieds, national rivers, and national monuments. However, information about other park units is not included in this particular dataset.\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\nThis particular dataset is drawn from data published by the NPS. Most (but not all) of the contextual information included here draws from material published by the NPS, as well. However, the original data is made available in an NPS data portal that is relatively hard to find, and its documentation is scattered across many different web pages, which is why we believe it is valuable to curate and publish it in a single place here.\nThis dataset was curated and published by Melanie Walsh, and the data essay was written by Os Keyes and Melanie Walsh."
  },
  {
    "objectID": "posts/np-data/index.html#history",
    "href": "posts/np-data/index.html#history",
    "title": "National Park Visitation Data",
    "section": "History",
    "text": "History\nThe National Park Service actually began recording information about park visits in 1904 (more than 100 years ago!). However, at this time, their visit collection methods were mostly informal, inconsistent, and low-tech. But over the next century, the NPS worked hard to make their data collection methods more reliable, consistent, and (in some but not all cases) high-tech.\nA big catalyst for the NPS getting serious about data collection was a new law. In 1965, the U.S. Congress passed a federal law that was very important for the NPS and for anybody who loves the outdoors: The Land and Water Conservation Fund Act of 1965. This act created a new source of government money specifically dedicated to protecting natural resources (i.e. to buying up land and water so that condo developers couldn’t do it first) and building up outdoor recreation infrastructure in the U.S.\nOne of the clauses in this act stipulated that the amount of money allocated to each recreation area should be “proportional to visitor use.” Because the NPS can’t function without money, they buckled down on counting visitor use. According to the NPS, over the next twenty years, they “developed and institutionalized a formal system for collecting, compiling and reporting visitor use data.”\nWhile today’s visit data collection system is far more formal and sophisticated than the one that the NPS used in 1904, there are still many inconsistencies, flaws, and limitations in this system. These shortcomings are largely unavoidable. Trying to record every single visit to a National Park — across dozens of different parks and geographic regions, many decades of time, countless different weather conditions and funding situations, and hundreds of millions of people — is pretty much impossible. In fact, one of the reasons that this dataset is so useful and illuminating is because it does a good job of communicating an important point: data can never reflect reality precisely.\nHowever, the NPS visitation data also does a good job of communicating why we might be interested in collecting and analyzing even flawed and approximate data, as we will dig into below."
  },
  {
    "objectID": "posts/np-data/index.html#where-did-the-data-come-from-who-collected-it",
    "href": "posts/np-data/index.html#where-did-the-data-come-from-who-collected-it",
    "title": "National Park Visitation Data",
    "section": "Where did the data come from? Who collected it?",
    "text": "Where did the data come from? Who collected it?\nThis National Park visitation data was originally organized and published by the NPS Social Science Program, a specific program tasked with coordinating visitor statistics across the parks. Thousands of staff members were also involved in the data collection process for individual parks, as we will elaborate below.\nThe original data was made available through the NPS Visitor Use Statistics data portal. Through this portal, you can generate reports and download data for many different park visitation categories and time periods— at both the national and individual park levels.\nTo download the data included here, we selected the “Query Builder for Public Use Statistics (1979 - Last Calendar Year)” report type. We then selected only National Parks; all possible years (1979-2022); all possible regions; only “Recreation Visits”; the additional fields of “State” and “Region”; as well as the option of an annual summary of visit counts (as opposed to monthly visit counts). We then downloaded this report as a CSV and published it to GitHub for easier access."
  },
  {
    "objectID": "posts/np-data/index.html#why-was-the-data-collected-how-is-the-data-used",
    "href": "posts/np-data/index.html#why-was-the-data-collected-how-is-the-data-used",
    "title": "National Park Visitation Data",
    "section": "Why was the data collected? How is the data used?",
    "text": "Why was the data collected? How is the data used?\nAs we’ve already discussed, one of the reasons that the NPS collects visit data is because the government basically requires it. But there are a lot of other reasons that the NPS collects this information.\nAs the NPS writes on their website, they use visit data to determine which facilities might need more or less attention, which parks might need more or less staff members and programs, and which hiking trails or bathrooms might need more or less maintenance. This information also helps the communities and businesses surrounding the parks understand how they can best share and support resources in a given area — services like emergency vehicles, sanitation, and water. If there are millions more people going on hikes in a particular area, and thus, inevitably, many more people requiring ambulance trips or rescue helicopters, that would be a very important thing for a community to know. It would be dangerous if visitors to National Parks suddenly and unexpectedly called all the emergency vehicles in town.\nThis visitation data also helps the NPS estimate the beneficial impact, economic and otherwise, that the parks have on nearby communities and the nation at large. These estimations are important because they help the parks advocate for more funding, support, attention, and collaboration.\n\nThe data can also be used for a variety of other purposes…. (such as?)"
  },
  {
    "objectID": "posts/np-data/index.html#whats-in-the-data-what-counts-as-a-visit",
    "href": "posts/np-data/index.html#whats-in-the-data-what-counts-as-a-visit",
    "title": "National Park Visitation Data",
    "section": "What’s in the data? What “counts” as a visit?",
    "text": "What’s in the data? What “counts” as a visit?\nIf we open the dataset and look at the first few rows, we will find five columns – “ParkName”, “Region”, “State”, “Year”, and “RecreationVisits”:\n\n\nCode\n# https://statsandr.com/blog/an-efficient-way-to-install-and-load-r-packages/\n\n# Load the dplyr package\nlibrary(dplyr, warn = FALSE)\n\n# Load National Park Visitation data\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\", stringsAsFactors = FALSE)\n\n## Look at the structure of the dataset\nnp_data %&gt;% slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nIsle Royale NP\nMidwest\nMI\n2018\n25798\n\n\nWhite Sands NP\nIntermountain\nNM\n2014\n503660\n\n\nIndiana Dunes NP\nMidwest\nIN\n1983\n1510630\n\n\nYosemite NP\nPacific West\nCA\n2010\n3901408\n\n\nGreat Sand Dunes NP & PRES\nIntermountain\nCO\n2018\n442905\n\n\nDry Tortugas NP\nSoutheast\nFL\n1990\n19402\n\n\nGateway Arch NP\nMidwest\nMO\n2014\n1817091\n\n\nIndiana Dunes NP\nMidwest\nIN\n1987\n1576238\n\n\nDenali NP & PRES\nAlaska\nAK\n1984\n395099\n\n\nLake Clark NP & PRES\nAlaska\nAK\n2012\n11639\n\n\n\n\n\n\nThe first four are self-explanatory: but why is the fifth labelled “RecreationVisits” rather than “Visits”, or “Visitors”?\nThe answer is that what this dataset is tracking is more complicated and nuanced than “people who go to NPS properties”. People go to the national parks for a lot of reasons. While many are there for recreation, some travel through the parks, either because a highway runs through or because they live on “inholdings” (private property that is surrounded by a national park on all sides). Because of this, the NPS defines “Recreation Visits” as visits made by people who are not:\n\nusing park territory, roads, and facilities for their own convenience or as a part of their occupation. &gt; Reportable non-recreation visits include:\n\nPersons going to and from inholdings across significant parts of park land;\nCommuter and other traffic using NPS-administered roads or waterways through a park for their convenience;\nTrades-people with business in the park;\nAny civilian activity a part of or incidental to the pursuit of a gainful occupation (e.g., guides);\nGovernment personnel (other than NPS employees) with business in the park;\nCitizens using NPS buildings for civic or local government business, or attending public hearings;\nOutside research activities (visits and overnights) if independent of NPS legislated interests (e.g. meteorological research).\n\n\nWhat this means is that the counts leave out a lot of people. This is worth thinking about when we evaluate what the numbers mean, and how the NPS achieves them (which we’ll discuss more below)"
  },
  {
    "objectID": "posts/np-data/index.html#data-and-data-collection",
    "href": "posts/np-data/index.html#data-and-data-collection",
    "title": "National Park Visitation Data",
    "section": "Data and data collection",
    "text": "Data and data collection\nSo now we know what is being collected. But let’s try to understand how it’s being collected. We can do this, in part, by exploring and visualising the data.\nFor example: let’s visualise the visits to Crater Lakes National Park, from 1979 to the present:\n\n\nCode\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette &lt;- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Crater Lake National Park\ncrater_lake &lt;- np_data %&gt;% filter(ParkName == \"Crater Lake NP\")\n\n# Visualize it\nggplot(data = crater_lake) + \n  geom_line(aes(x = \n  Year, y = RecreationVisits), \n  color = cb_palette[1]) +\n  labs(title = \"Crater Lake National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nWe see a lot of things in this data - not least of which is a tremendous rise in visitors in the 2010s - but one interesting observation is the sudden drop in visits in 2012. This isn’t caused by fewer people visiting: instead, it has more to do with how visitor numbers are counted.\nWhen it comes to counting visitors, the NPS uses a variety of techniques. At some parks, such as Alcatraz, it is simple: the park is only accessible via (ticketed) boat, and so NPS staff simply count the number of tickets. But other parks may have multiple entrances, and feature visitors arriving via car, bus, or on foot. It quickly becomes impractical to have staff at every entrance, 24 hours a day, just in case someone arrives.\nInstead, the NPS uses a variety of techniques - some automated, some manual. These include:\n\nInduction loop counters - magnetised coils of wire under the road that “trip” when a vehicle passes over them;\nTraffic counters, which manually increment a counter when a vehicle passes through a gate;\nExtracting data from ticketing machines.\n\n\n\n\nAn example of an induction loop installed under a road\n\n\nAlongside all of that, NPS rangers do, on many occasions, manually count people who arrive - particularly when one of the usual mechanisms doesn’t count. And that’s exactly what happened here; according to the NPS data logs, the induction loop counter at one of the main entrances simply broke in January, and wasn’t repaired for (at a minimum) several months. You can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears visits entirely tail off in 2020, as a result of the traffic counter being broken for years:\n\n\nCode\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data &lt;- np_data %&gt;% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")"
  },
  {
    "objectID": "posts/np-data/index.html#exercise-thinking-about-where-and-how-and-why-mechanisms-are-likely-to-break",
    "href": "posts/np-data/index.html#exercise-thinking-about-where-and-how-and-why-mechanisms-are-likely-to-break",
    "title": "National Park Visitation Data",
    "section": "Exercise: thinking about where (and how, and why) mechanisms are likely to break",
    "text": "Exercise: thinking about where (and how, and why) mechanisms are likely to break\nNow that we’ve talked about how data is collected (and the fragility of some of those methods), it’s a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see Exercise 1."
  },
  {
    "objectID": "posts/np-data/index.html#data-and-reality",
    "href": "posts/np-data/index.html#data-and-reality",
    "title": "National Park Visitation Data",
    "section": "Data and reality",
    "text": "Data and reality\nChanges in data don’t only stem from changes in data collection, but also the underlying reality of what is being measured. Let’s take a look at the visitor data from Kobuk Valley National Park:\n\n\nCode\n# Filter down to Kobuk Valley National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[3]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nMost people’s eyes will immediately be drawn to the drastic drop in 2014-15, and for good reason! But the cause is familiar: it’s about data collection. As the park report notes, ” The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.“.\nBut another question would be: why the drop-off in 2018-19? It’s too early for the cause to be COVID. Instead, the cause is administrative; government shut-downs in that era led to a reduction of funding, and correspondingly the closure of various attractions at the park. The result: a lack of funding leads to a reduced visitor count - a visitor count that is often used, remember, to argue for funding. This highlights one of the ways in which seemingly-descriptive data used to make decisions can represent the state of those decisions, more than some natural “baseline”.\nAnother kind of issue of “representing reality” can be found if we look at the visitor data for Mount Rainier:\n\n\nCode\n# Filter down to Mount Rainier National Park\nrainier_data &lt;- np_data %&gt;% filter(ParkName == \"Mount Rainier NP\")\n\n# Visualise it\nggplot(data = rainier_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[4]) +\n  labs(title = \"Mount Rainier National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nOnce again, we see both a COVID-19 dropoff - but also a continued dropoff beyond that. Looking at the visitation comments explains why; flooding, fires and a blizzard drastically impeded the ability of people to get to the park, and the possibility of areas of the park opening at all."
  },
  {
    "objectID": "posts/np-data/index.html#compensating-for-data",
    "href": "posts/np-data/index.html#compensating-for-data",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "As all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of any data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\nSometimes this leads to odd-looking decisions. For example: at Assateague Island National Seashore, there are two entrances (one in Maryland, and one in Virginia). At both entrances, they use a traffic counter to count vehicles. At both entrances, they get from vehicles to visitors by multiplying the number of vehicles by an estimate of how many people each vehicle contains. But at the Maryland entrance, that’s 2.9. At the Virginia entrance, it’s 3.2."
  },
  {
    "objectID": "posts/np-data/index.html#exercise-compensating-for-data-outages",
    "href": "posts/np-data/index.html#exercise-compensating-for-data-outages",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Reader note: this exercise will direct students, on a group (or individual) basis, to the NPS index of how different parks calculate different multipliers and metrics, and ask them to log or note unusual or unexplained differences in how this is done."
  },
  {
    "objectID": "posts/np-data/index.html#data-decisions",
    "href": "posts/np-data/index.html#data-decisions",
    "title": "National Park Visitation Data",
    "section": "Data decisions",
    "text": "Data decisions\nAs well as multiplying up, there’s also counting down: some parks register “zero” as the number of visitors they attracted in a year:\n\n\nCode\n# Filter down to just zeros\nzero_data &lt;- np_data %&gt;% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\n\n\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has “zero counts”, Kobuk Valley National park, we see it’s hardly overrun with people even when the count isn’t zero:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nIf we look at the visitation comments again, what we see is that “The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” Which is entirely reasonable, in isolation: but we’ve also seen a lot of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?"
  },
  {
    "objectID": "posts/np-data/index.html#look-at-the-structure-of-the-dataset",
    "href": "posts/np-data/index.html#look-at-the-structure-of-the-dataset",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Code\n# Filter down to just zeros\nzero_data &lt;- np_data %&gt;% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\n\n\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has “zero counts”, Kobuk Valley National park, we see it’s hardly overrun with people even when the count isn’t zero:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nIf we look at the visitation comments again, what we see is that “The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” Which is entirely reasonable, in isolation: but we’ve also seen a lot of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?"
  },
  {
    "objectID": "posts/np-data/index.html#exercise-data-decisions",
    "href": "posts/np-data/index.html#exercise-data-decisions",
    "title": "National Park Visitation Data",
    "section": "Exercise: data decisions",
    "text": "Exercise: data decisions\nReader note: in this exercise, users will try to use public data - twitter posts, flickr photos, etc, etc - to try and find situations where people are identifying themselves as being at a park that, officially, has 0 people present at that time Have them go through public data and try to find proof the counts of 0 are “wrong”"
  },
  {
    "objectID": "posts/np-data/index.html#exercise-1",
    "href": "posts/np-data/index.html#exercise-1",
    "title": "National Park Visitation Data",
    "section": "Activity 1",
    "text": "Activity 1\nDevices breaking is inevitable - but as the different scales of the Carlsbad and Crater Lake outages indicate, they get fixed at different rates, in different locations. There are a lot of reasons for this, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it—and the less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritised by the repair teams that can be dispatched.\nThinking about this, look at the locations of the following parks. Suppose that each one has an outage in their induction loop: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n\n\nPark\nPriority (1-5)\nReason\n\n\n\n\nAcadia NP\n\n\n\n\nLassen Volcanic NP\n\n\n\n\nSaguaro NP\n\n\n\n\nYosemite NP\n\n\n\n\nMammoth Cave NP"
  },
  {
    "objectID": "get-involved.html",
    "href": "get-involved.html",
    "title": "Get Involved",
    "section": "",
    "text": "Get Involved"
  },
  {
    "objectID": "mission.html",
    "href": "mission.html",
    "title": "Mission",
    "section": "",
    "text": "Mission"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP.html",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP.html",
    "title": "Introduction to DPLYR with National Park Visitation Data",
    "section": "",
    "text": "Download as R Script\nSolutions"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP.html#introduction-to-dplyr-with-national-park-visitation-data",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP.html#introduction-to-dplyr-with-national-park-visitation-data",
    "title": "Introduction to DPLYR with National Park Visitation Data",
    "section": "",
    "text": "Download as R Script\nSolutions"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Download as R Script\n Exercise Without Solutions \n\n\n\n\nCode\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\",\n stringsAsFactors = FALSE)\n\n\nView the np_data dataframe by clicking on the spreadsheet icon in the Global Environment\n\n\n\n\n\nCode\ninstall.packages(\"tidyverse\")\n\n\n\n\n\n\n\nCode\nlibrary(dplyr)\n\n\n\n\n\nSelect 2 columns from the data using a DPLYR function.\nSave this 2-column dataframe to the variable smaller_df.\nMake sure to use the pipe %&gt;% operator!\n\n\nCode\nsmaller_df &lt;- np_data %&gt;% select(Year, RecreationVisits)\n\nhead(smaller_df)\n\n\n\n\n\n\nYear\nRecreationVisits\n\n\n\n\n1979\n2787366\n\n\n1980\n2779666\n\n\n1981\n2997972\n\n\n1982\n3572114\n\n\n1983\n4124639\n\n\n1984\n3734763"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#load-national-park-visitation-data",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#load-national-park-visitation-data",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Code\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\",\n stringsAsFactors = FALSE)\n\n\nView the np_data dataframe by clicking on the spreadsheet icon in the Global Environment"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#install-tidyverse",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#install-tidyverse",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Code\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#load-dplyr-library",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#load-dplyr-library",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Code\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#exercise-1",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#exercise-1",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Select 2 columns from the data using a DPLYR function.\nSave this 2-column dataframe to the variable smaller_df.\nMake sure to use the pipe %&gt;% operator!\n\n\nCode\nsmaller_df &lt;- np_data %&gt;% select(Year, RecreationVisits)\n\nhead(smaller_df)\n\n\n\n\n\n\nYear\nRecreationVisits\n\n\n\n\n1979\n2787366\n\n\n1980\n2779666\n\n\n1981\n2997972\n\n\n1982\n3572114\n\n\n1983\n4124639\n\n\n1984\n3734763"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#exercise-2",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#exercise-2",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "Exercise 2",
    "text": "Exercise 2\nFilter the dataframe for only values in the state of Washington and save to the variable wa_parks\n\n\nCode\nwa_parks &lt;- np_data %&gt;% filter(State == \"WA\")\n\nhead(wa_parks)\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nMount Rainier NP\nPacific West\nWA\n1979\n1516703\n\n\nMount Rainier NP\nPacific West\nWA\n1980\n1268256\n\n\nMount Rainier NP\nPacific West\nWA\n1981\n1233671\n\n\nMount Rainier NP\nPacific West\nWA\n1982\n1007300\n\n\nMount Rainier NP\nPacific West\nWA\n1983\n1106306\n\n\nMount Rainier NP\nPacific West\nWA\n1984\n1152411"
  },
  {
    "objectID": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#exercise-3",
    "href": "posts/np-data/exercises/Intro-to-DPLYR-NP-Solutions.html#exercise-3",
    "title": "Introduction to DPLYR with National Park Visitation Data (Solution)",
    "section": "Exercise 3",
    "text": "Exercise 3\nCalculate the sum total of RecreationVisits to Washington by using summarize() on the smaller dataframe wa_parks\n\n\nCode\nwa_parks %&gt;% summarize(sum(RecreationVisits))\n\n\n\n\n\n\nsum(RecreationVisits)\n\n\n\n\n188798152"
  },
  {
    "objectID": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html",
    "href": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html",
    "title": "ggplot Customization with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Download as R Script\n Exercise Without Solutions \n\n\n\n\nCode\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2022-National-Park-Visits-By-State.csv\",\n stringsAsFactors = FALSE)\n\n\nView the np_data dataframe by clicking on the spreadsheet icon in the Global Environment\n\n\n\n\n\nCode\nlibrary(\"dplyr\")\nlibrary(\"stringr\")\nlibrary(\"ggplot2\")\nlibrary(\"scales\")\n\n\n\nHow have visits to a particular National Park changed over time?\nWhat is the most interesting period of change?"
  },
  {
    "objectID": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html#load-national-park-visitation-data",
    "href": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html#load-national-park-visitation-data",
    "title": "ggplot Customization with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Code\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2022-National-Park-Visits-By-State.csv\",\n stringsAsFactors = FALSE)\n\n\nView the np_data dataframe by clicking on the spreadsheet icon in the Global Environment"
  },
  {
    "objectID": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html#load-libraries",
    "href": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html#load-libraries",
    "title": "ggplot Customization with National Park Visitation Data (Solution)",
    "section": "",
    "text": "Code\nlibrary(\"dplyr\")\nlibrary(\"stringr\")\nlibrary(\"ggplot2\")\nlibrary(\"scales\")\n\n\n\nHow have visits to a particular National Park changed over time?\nWhat is the most interesting period of change?"
  },
  {
    "objectID": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html#exercise-3",
    "href": "posts/np-data/exercises/Ggplot-Customization-NP-Solutions.html#exercise-3",
    "title": "ggplot Customization with National Park Visitation Data (Solution)",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow, create a plot that zooms in on the most interesting time period for this particular National Park.\n\n3a.\nChange the x-axis limits so that it only shows the most interesting years.\n\n\n3b.\nCome up with a new title that describes this time period.\n\n\nCode\nggplot(my_parks_df) +\n  geom_line(aes(\n    x = Year,\n    y = RecreationVisits\n  ),\n  color = \"green\") +\n  scale_x_continuous(\n    breaks = seq(from = 1980, to = 2020, by = 5), \n    limits = c(2005, 2023),\n  ) +\n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()),\n   limits = c(0, 2000000)) +\n  labs(title = \"After a COVID Dip, Mt. Rainier Visits Are Higher Than Ever\")"
  },
  {
    "objectID": "posts/gender-violence/index.html",
    "href": "posts/gender-violence/index.html",
    "title": "Gender Violence at the Border",
    "section": "",
    "text": "Data EssayDataExercises\n\n\nThese datasets include information about gender violence and feminicides at the U.S-Mexico Border.\n\n\n\n\nCode\nviewof search = Inputs.search(data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\nCode\ndata = d3.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2022-National-Park-Visits-By-State.csv\", d3.autoType)\n\n\n\n\n\n\n\n\n\nCode\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\n\n\nCode\ncolor = d3\n  .scaleLinear()\n  .domain([500000, 100000, 10000])\n  .range([\"#cafcc2\", \"#fce7c2\", \"#eb9494\"])\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})"
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Team",
    "section": "",
    "text": "“Responsible Datasets in Context: Collaboratively Designing for Ethical Humanities Data Education” is supported by the the Responsible Computing Challenge, which is a partnership between Mozilla, Omidyar Network, Schmidt Futures, Craig Newmark Philanthropies, Mellon Foundation, and the Rockefeller Brothers Fund.\n\nProject Directors\n\nSylvia Fernández, PI\nMiriam Posner, PI\nAnna Preus, PI\nAmardeep Singh, PI\nMelanie Walsh, PI\n\n\n\nTeam Members\n\nOs Keyes\nKatherine Hennessey\nAashna Sheth\nPaulina Hernandez Trejo"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Responsible Datasets in Context",
    "section": "",
    "text": "Responsible Datasets in Context\nStar this project on Github\n\nThis website contains a repository of curated datasets that are paired with rich documentation, related essays, and teaching resources.\nWe dig into the social and historical context of each dataset, and we provide extensive documentation about the data’s provenance and limitations. We also include teaching resources for each dataset—such as programming exercises, discussion questions, lessons plans, and more—to enable their seamless integration into the classroom.\nBy providing these contextual materials, we hope to promote the responsible use of these particular datasets for teaching, research, and general exploration. We also seek to promote the responsible use of data more broadly—whether in the classroom, industry, or the wider world—by underscoring the significance of context in all data-related work.\n\n\n\n\n🚧 Website Under Construction 🚧\nThis website is currently under construction. Stay tuned for announcements about its official publication.\n\n\n\n\n\nDatasets\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLibrary Top 500\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nAnna Preus and Aashna Sheth\n\n\n\n\n\n\n\n\n\n\n\n\nU.S. National Park Visit Data\n\n\n\n\n\n\n\n\n\n\n\nMar 9, 2024\n\n\nMelanie Walsh and Os Keyes\n\n\n\n\n\n\n\n\n\n\n\n\nGender Violence at the Border\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nSylvia Fernández and Paulina Hernandez Trejo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/np-data/index.html#data-compensating",
    "href": "posts/np-data/index.html#data-compensating",
    "title": "National Park Visitation Data",
    "section": "Compensating for data",
    "text": "Compensating for data\nAs all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of any data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\nSometimes this leads to odd-looking decisions. For example: at Assateague Island National Seashore, there are two entrances (one in Maryland, and one in Virginia). At both entrances, they use a traffic counter to count vehicles. At both entrances, they get from vehicles to visitors by multiplying the number of vehicles by an estimate of how many people each vehicle contains. But at the Maryland entrance, that’s 2.9. At the Virginia entrance, it’s 3.2. We will talk about that more in our second exercise."
  },
  {
    "objectID": "posts/np-data/index.html#exercise-2",
    "href": "posts/np-data/index.html#exercise-2",
    "title": "National Park Visitation Data",
    "section": "Activity 2",
    "text": "Activity 2\nIn “compensating for data”, we talked about how the NPS fills in missing data or approximates data with uncertain values (such as the number of people per car). This is necessary work, but it’s also under-explained work in the examples we used - and it goes far beyond those examples.\nTo see this in action, take a look at the NPS page that documents park reports and select a park. You’ll see, with most of the parks, that one possible report covers “Visitor Use Counting Procedures”. Open it, and look at how the NPS calculates visitors for that park; if you do this with multiple parks, you can see the (often-unexplained) variations between different parks’ procedures."
  },
  {
    "objectID": "posts/np-data/with-tabs.html",
    "href": "posts/np-data/with-tabs.html",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Data EssayExplore the DataExercisesDiscussion & Activities\n\n\n\n\nThis dataset contains the number of visits, per year, to each of the 63 National Parks administered by the United States National Park Service (NPS), from 1979 to the present. The NPS also collects visitation data for other park units, such as national battlfieds, national rivers, and national monuments. However, information about other park units is not included in this particular dataset.\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\nThis particular dataset is drawn from data published by the NPS. Most (but not all) of the contextual information included here draws from material published by the NPS, as well. However, the original data is made available in an NPS data portal that is relatively hard to find, and its documentation is scattered across many different web pages, which is why we believe it is valuable to curate and publish it in a single place here.\nThis dataset was curated and published by Melanie Walsh, and the data essay was written by Os Keyes and Melanie Walsh.\n\n\n\nThe National Park Service actually began recording information about park visits in 1904 (more than 100 years ago!). However, at this time, their visit collection methods were mostly informal, inconsistent, and low-tech. But over the next century, the NPS worked hard to make their data collection methods more reliable, consistent, and (in some but not all cases) high-tech.\nA big catalyst for the NPS getting serious about data collection was a new law. In 1965, the U.S. Congress passed a federal law that was very important for the NPS and for anybody who loves the outdoors: The Land and Water Conservation Fund Act of 1965. This act created a new source of government money specifically dedicated to protecting natural resources (i.e. to buying up land and water so that condo developers couldn’t do it first) and building up outdoor recreation infrastructure in the U.S.\nOne of the clauses in this act stipulated that the amount of money allocated to each recreation area should be “proportional to visitor use.” Because the NPS can’t function without money, they buckled down on counting visitor use. According to the NPS, over the next twenty years, they “developed and institutionalized a formal system for collecting, compiling and reporting visitor use data.”\nWhile today’s visit data collection system is far more formal and sophisticated than the one that the NPS used in 1904, there are still many inconsistencies, flaws, and limitations in this system. These shortcomings are largely unavoidable. Trying to record every single visit to a National Park — across dozens of different parks and geographic regions, many decades of time, countless different weather conditions and funding situations, and hundreds of millions of people — is pretty much impossible. In fact, one of the reasons that this dataset is so useful and illuminating is because it does a good job of communicating an important point: data can never reflect reality precisely.\nHowever, the NPS visitation data also does a good job of communicating why we might be interested in collecting and analyzing even flawed and approximate data, as we will dig into below.\n\n\n\nThis National Park visitation data was originally organized and published by the NPS Social Science Program, a specific program tasked with coordinating visitor statistics across the parks. Thousands of staff members were also involved in the data collection process for individual parks, as we will elaborate below.\nThe original data was made available through the NPS Visitor Use Statistics data portal. Through this portal, you can generate reports and download data for many different park visitation categories and time periods— at both the national and individual park levels.\nTo download the data included here, we selected the “Query Builder for Public Use Statistics (1979 - Last Calendar Year)” report type. We then selected only National Parks; all possible years (1979-2022); all possible regions; only “Recreation Visits”; the additional fields of “State” and “Region”; as well as the option of an annual summary of visit counts (as opposed to monthly visit counts). We then downloaded this report as a CSV and published it to GitHub for easier access.\n\n\n\n\nAs we’ve already discussed, one of the reasons that the NPS collects visit data is because the government basically requires it. But there are a lot of other reasons that the NPS collects this information.\nAs the NPS writes on their website, they use visit data to determine which facilities might need more or less attention, which parks might need more or less staff members and programs, and which hiking trails or bathrooms might need more or less maintenance. This information also helps the communities and businesses surrounding the parks understand how they can best share and support resources in a given area — services like emergency vehicles, sanitation, and water. If there are millions more people going on hikes in a particular area, and thus, inevitably, many more people requiring ambulance trips or rescue helicopters, that would be a very important thing for a community to know. It would be dangerous if visitors to National Parks suddenly and unexpectedly called all the emergency vehicles in town.\nThis visitation data also helps the NPS estimate the beneficial impact, economic and otherwise, that the parks have on nearby communities and the nation at large. These estimations are important because they help the parks advocate for more funding, support, attention, and collaboration.\n\nThe data can also be used for a variety of other purposes…. (such as?)\n\n\n\nIf we open the dataset and look at the first few rows, we will find five columns – “ParkName”, “Region”, “State”, “Year”, and “RecreationVisits”:\n\n\nCode\n# https://statsandr.com/blog/an-efficient-way-to-install-and-load-r-packages/\n\n# Load the dplyr package\nlibrary(dplyr, warn = FALSE)\n\n# Load National Park Visitation data\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\", stringsAsFactors = FALSE)\n\n## Look at the structure of the dataset\nnp_data %&gt;% slice_sample(n = 10)\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\nWind Cave NP\nMidwest\nSD\n1994\n871061\n\n\nDeath Valley NP\nPacific West\nCA\n2014\n1101312\n\n\nBiscayne NP\nSoutheast\nFL\n1989\n589957\n\n\nSequoia NP\nPacific West\nCA\n1993\n1066552\n\n\nDry Tortugas NP\nSoutheast\nFL\n2003\n74741\n\n\nBig Bend NP\nIntermountain\nTX\n2008\n362512\n\n\nGuadalupe Mountains NP\nIntermountain\nTX\n1999\n219591\n\n\nBiscayne NP\nSoutheast\nFL\n2020\n402770\n\n\nMount Rainier NP\nPacific West\nWA\n2003\n1262351\n\n\n\n\n\n\nThe first four are self-explanatory: but why is the fifth labelled “RecreationVisits” rather than “Visits”, or “Visitors”?\nThe answer is that what this dataset is tracking is more complicated and nuanced than “people who go to NPS properties”. People go to the national parks for a lot of reasons. While many are there for recreation, some travel through the parks, either because a highway runs through or because they live on “inholdings” (private property that is surrounded by a national park on all sides). Because of this, the NPS defines “Recreation Visits” as visits made by people who are not:\n\nusing park territory, roads, and facilities for their own convenience or as a part of their occupation. &gt; Reportable non-recreation visits include:\n\nPersons going to and from inholdings across significant parts of park land;\nCommuter and other traffic using NPS-administered roads or waterways through a park for their convenience;\nTrades-people with business in the park;\nAny civilian activity a part of or incidental to the pursuit of a gainful occupation (e.g., guides);\nGovernment personnel (other than NPS employees) with business in the park;\nCitizens using NPS buildings for civic or local government business, or attending public hearings;\nOutside research activities (visits and overnights) if independent of NPS legislated interests (e.g. meteorological research).\n\n\nWhat this means is that the counts leave out a lot of people. This is worth thinking about when we evaluate what the numbers mean, and how the NPS achieves them (which we’ll discuss more below)\n\n\n\nSo now we know what is being collected. But let’s try to understand how it’s being collected. We can do this, in part, by exploring and visualising the data.\nFor example: let’s visualise the visits to Crater Lakes National Park, from 1979 to the present:\n\n\nCode\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette &lt;- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Crater Lake National Park\ncrater_lake &lt;- np_data %&gt;% filter(ParkName == \"Crater Lake NP\")\n\n# Visualize it\nggplot(data = crater_lake) + \n  geom_line(aes(x = \n  Year, y = RecreationVisits), \n  color = cb_palette[1]) +\n  labs(title = \"Crater Lake National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nWe see a lot of things in this data - not least of which is a tremendous rise in visitors in the 2010s - but one interesting observation is the sudden drop in visits in 2012. This isn’t caused by fewer people visiting: instead, it has more to do with how visitor numbers are counted.\nWhen it comes to counting visitors, the NPS uses a variety of techniques. At some parks, such as Alcatraz, it is simple: the park is only accessible via (ticketed) boat, and so NPS staff simply count the number of tickets. But other parks may have multiple entrances, and feature visitors arriving via car, bus, or on foot. It quickly becomes impractical to have staff at every entrance, 24 hours a day, just in case someone arrives.\nInstead, the NPS uses a variety of techniques - some automated, some manual. These include:\n\nInduction loop counters - magnetised coils of wire under the road that “trip” when a vehicle passes over them;\nTraffic counters, which manually increment a counter when a vehicle passes through a gate;\nExtracting data from ticketing machines.\n\n\n\n\nAn example of an induction loop installed under a road\n\n\nAlongside all of that, NPS rangers do, on many occasions, manually count people who arrive - particularly when one of the usual mechanisms doesn’t count. And that’s exactly what happened here; according to the NPS data logs, the induction loop counter at one of the main entrances simply broke in January, and wasn’t repaired for (at a minimum) several months. You can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears visits entirely tail off in 2020, as a result of the traffic counter being broken for years:\n\n\nCode\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data &lt;- np_data %&gt;% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\n\n\n\nNow that we’ve talked about how data is collected (and the fragility of some of those methods), it’s a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see Exercise 1.\n\n\n\nChanges in data don’t only stem from changes in data collection, but also the underlying reality of what is being measured. Let’s take a look at the visitor data from Kobuk Valley National Park:\n\n\nCode\n# Filter down to Kobuk Valley National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[3]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nMost people’s eyes will immediately be drawn to the drastic drop in 2014-15, and for good reason! But the cause is familiar: it’s about data collection. As the park report notes, ” The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.“.\nBut another question would be: why the drop-off in 2018-19? It’s too early for the cause to be COVID. Instead, the cause is administrative; government shut-downs in that era led to a reduction of funding, and correspondingly the closure of various attractions at the park. The result: a lack of funding leads to a reduced visitor count - a visitor count that is often used, remember, to argue for funding. This highlights one of the ways in which seemingly-descriptive data used to make decisions can represent the state of those decisions, more than some natural “baseline”.\nAnother kind of issue of “representing reality” can be found if we look at the visitor data for Mount Rainier:\n\n\nCode\n# Filter down to Mount Rainier National Park\nrainier_data &lt;- np_data %&gt;% filter(ParkName == \"Mount Rainier NP\")\n\n# Visualise it\nggplot(data = rainier_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[4]) +\n  labs(title = \"Mount Rainier National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nOnce again, we see both a COVID-19 dropoff - but also a continued dropoff beyond that. Looking at the visitation comments explains why; flooding, fires and a blizzard drastically impeded the ability of people to get to the park, and the possibility of areas of the park opening at all.\n\n\n\nAs all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of any data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\nSometimes this leads to odd-looking decisions. For example: at Assateague Island National Seashore, there are two entrances (one in Maryland, and one in Virginia). At both entrances, they use a traffic counter to count vehicles. At both entrances, they get from vehicles to visitors by multiplying the number of vehicles by an estimate of how many people each vehicle contains. But at the Maryland entrance, that’s 2.9. At the Virginia entrance, it’s 3.2. We will talk about that more in our second exercise.\n\n\n\nAs well as multiplying up, there’s also counting down: some parks register “zero” as the number of visitors they attracted in a year:\n\n\nCode\n# Filter down to just zeros\nzero_data &lt;- np_data %&gt;% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\n\n\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has “zero counts”, Kobuk Valley National park, we see it’s hardly overrun with people even when the count isn’t zero:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nIf we look at the visitation comments again, what we see is that “The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” Which is entirely reasonable, in isolation: but we’ve also seen a lot of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?\n\n\n\nReader note: in this exercise, users will try to use public data - twitter posts, flickr photos, etc, etc - to try and find situations where people are identifying themselves as being at a park that, officially, has 0 people present at that time Have them go through public data and try to find proof the counts of 0 are “wrong”\n\n\n\n\n\nCode\nviewof search = Inputs.search(data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\nCode\ndata = d3.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2022-National-Park-Visits-By-State.csv\", d3.autoType)\n\n\n\n\n\n\n\n\n\nCode\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\n\n\nCode\ncolor = d3\n  .scaleLinear()\n  .domain([5000000, 1000000, 100000])\n  .range([\"#cafcc2\", \"#fce7c2\", \"#eb9494\"])\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n\n\n\nRPython\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\nFeb 26, 2024\n\n\nIntroduction to DPLYR with National Park Visitation Data (Solution)\n\n\ndplyr, solution\n\n\n\n\nFeb 26, 2024\n\n\nggplot Customization with National Park Visitation Data (Solution)\n\n\nggplot, advanced, solution\n\n\n\n\nFeb 26, 2024\n\n\nIntroduction to DPLYR with National Park Visitation Data (Exercise)\n\n\ndplyr, exercise, solution\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\nDevices breaking is inevitable - but as the different scales of the Carlsbad and Crater Lake outages indicate, they get fixed at different rates, in different locations. There are a lot of reasons for this, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it—and the less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritised by the repair teams that can be dispatched.\nThinking about this, look at the locations of the following parks. Suppose that each one has an outage in their induction loop: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n\n\nPark\nPriority (1-5)\nReason\n\n\n\n\nAcadia NP\n\n\n\n\nLassen Volcanic NP\n\n\n\n\nSaguaro NP\n\n\n\n\nYosemite NP\n\n\n\n\nMammoth Cave NP\n\n\n\n\n\n\n\n\nIn “compensating for data”, we talked about how the NPS fills in missing data or approximates data with uncertain values (such as the number of people per car). This is necessary work, but it’s also under-explained work in the examples we used - and it goes far beyond those examples.\nTo see this in action, take a look at the NPS page that documents park reports and select a park. You’ll see, with most of the parks, that one possible report covers “Visitor Use Counting Procedures”. Open it, and look at how the NPS calculates visitors for that park; if you do this with multiple parks, you can see the (often-unexplained) variations between different parks’ procedures."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#introduction",
    "href": "posts/np-data/with-tabs.html#introduction",
    "title": "U.S. National Park Visit Data",
    "section": "Introduction",
    "text": "Introduction\nThis dataset contains the number of visits, per year, to each of the current 63 National Parks administered by the United States National Park Service (NPS), from 1979 to the present. The NPS also collects visitation and use data about other park units, such as national battlfieds, national rivers, and national monuments. However, information about other park units is not included in this particular dataset.\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data  \nThe National Park datasets included on this website are drawn from data published by the NPS. Most (but not all) of the contextual information included here draws from material published by the NPS, as well. However, the original data is made available in an NPS data portal that is relatively hard to find, and the documentation is distributed across many different web pages, PDFs, and other documents, so we believe it is valuable to curate and publish in a single place here.\nThe datasets were curated and published by Melanie Walsh, and the data essay was written by Os Keyes and Melanie Walsh."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#history",
    "href": "posts/np-data/with-tabs.html#history",
    "title": "U.S. National Park Visit Data",
    "section": "History",
    "text": "History\nThe very first National Park — Yellowstone National Park, in Wyoming — was signed into law by President Ulysses S. Grant in 1872. A handful of other parks — Sequoia, Yosemite, Mt. Rainier, Crater Lake — joined the system in the next several decades. While the National Parks were originally created to protect precious, beautiful lands and to make them accessible to the public — a noble goal — it’s important to remember that these lands were taken, often forcibly, from Native American people who already owned, lived, and worked on them (Beauchamp 2020). Today, there are still calls for the NPS to return the lands of the National Parks to Indigenous people.\nScholars have similarly shown that early conservation movements, which spurred the development of the National Parks, were troublingly intertwined with racism and eugenics movements (Beauchamp 2020). These prejudiced origins, combined with continuing forms of environmental racism, have contributed to the marginalization of people of color and other minorities in the parks — in other words, research has shown that white people visit the parks much more than other demographic groups(Weber and Sultana 2013; Alba et al. 2022; Floyd and Johnson 2002). The National Parks are not equally accessible to everyone in the same way, and these exclusions shape the park visitation data even before it’s counted.\nVisit counting, according to the NPS, started a long time ago — as early as 1904 (more than 10 years before the National Park Service itself was officially created). However, at this time, their data collection methods were mostly “informal,” inconsistent, and low-tech. But over the next century, the NPS worked hard to make their methods more reliable, consistent, and (in some but not all cases) technologically advanced.\nA big catalyst for the NPS getting serious about data collection was a new law. In 1965, the U.S. Congress passed The Land and Water Conservation Fund Act of 1965. This act created a new source of government money specifically dedicated to protecting natural resources (i.e. to buying up more land and water so that condo developers couldn’t do it first) and to expanding outdoor recreation infrastructure in the U.S.\nBecause this act stipulated that the amount of money allocated to each area should be “proportional to visitor use,” the NPS buckled down on counting visitor use. Over the next twenty years, they accordingly “developed and institutionalized a formal system for collecting, compiling and reporting visitor use data.”\nWhile today’s National Park data collection system is more formal and sophisticated than the one that the NPS used in 1904, there are still many inconsistencies, flaws, and limitations in this system. And these shortcomings are largely unavoidable. Trying to record every single visit to a National Park — across dozens of different parks and geographic regions; many decades of time; countless changing weather conditions; a great deal of economic and financial fluctuation; and hundreds of millions of people — is pretty much impossible. We believe this data is useful to study, in fact, because it helps demonstrate that data never reflects reality precisely.\nHowever, the National Park visit data also demonstrates why collecting and analyzing data, even if it is flawed and approximate, is sometimes worthwhile — if you fully understand the data’s flaws, limitations, and history, and if you incorporate these considerations into all subsequent analyses, interpretations, and takeaways."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#where-did-the-data-come-from-who-collected-it",
    "href": "posts/np-data/with-tabs.html#where-did-the-data-come-from-who-collected-it",
    "title": "U.S. National Park Visit Data",
    "section": "Where did the data come from? Who collected it?",
    "text": "Where did the data come from? Who collected it?\nThe National Park data on this website was originally organized and published by the NPS Social Science Program, a specific program tasked with coordinating visitor statistics across the parks. Thousands of staff members across all 63 parks were also involved in the data collection process.\nThe original data was made available through the NPS’s Visitor Use Statistics data portal. Through this portal, you can generate reports and download data for many different park visitation categories and time periods — at both national and individual park levels. To download the data included here, we first selected “National Reports” in the data portal, and we then selected the “Query Builder for Public Use Statistics (1979 - Last Calendar Year)” report type.\n\n\n\n\n\n\nFigure 1: Selections for National Park visit data generated with “Query Builder for Public Use Statistics (1979 - Last Calendar Year)”\n\n\n\nFor “Park Types,” we selected only “National Parks”; for “Years,” we selected all possible years (1979-2023); for “Regions,” we selected all possible regions; for “Field Type,” we selected only “Recreation Visits” (excluding “NonRecreation Visits,”” “Recreation Hours,” “NonRecreation Hours,” “Concessioner Lodging,” “Concessioner Camping,” “Tent Campers,” “RV Campers,” “Backcountry Campers,” “NonRecreation Overnight Stays,” and “Miscellaneous Overnight Stays”); for “Additional Fields,” we selected “State” and “Region”. We also selected the option of viewing the report as an annual summary of visit counts (as opposed to monthly visit counts).\nIf you choose to download this report as a CSV file, it will unfortunately not look exactly like the report pictured in Figure 1; instead, the CSV will include all visit and use types, and it will include visit/use information by month rather than aggregated by year. When I have compiled this data to share with my students in the past, I have sometimes downloaded the CSV file and then removed the columns that I’m not interested in and aggregated the data by year programatically. In other cases, I have simply copied and pasted the annual summary report into a CSV file.\nIn either case, it is usually necessary to explicitly transform the format of the “RecreationVisits” column into a number and to remove the commas that separate the numbers by thousands (a transformation that you can do with spreadsheet applications like Excel or Google Sheets or with a programming language) Finally, we published the data to this project’s GitHub repository for easier storage and access."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#why-was-the-data-collected-how-is-the-data-used",
    "href": "posts/np-data/with-tabs.html#why-was-the-data-collected-how-is-the-data-used",
    "title": "U.S. National Park Visit Data",
    "section": "Why was the data collected? How is the data used?",
    "text": "Why was the data collected? How is the data used?\nThe NPS collects visit data partly because the government requires it, as we’ve already discussed. But the NPS also uses the visit data for other internal purposes — to determine which parks need more staff members and programming, which hiking trails need more maintenance, or which visitor centers need more bathrooms.\nThe visit data also helps the communities and businesses surrounding the parks understand how they can best provide and share resources, like emergency vehicles, sanitation, and water. If millions more hikers started to come to Mt. Rainier, for example, that would be a very important thing for the surrounding community to know. To consider just one consequence of this increase, those hikers would likely need more ambulance trips and rescue helicopters, and you wouldn’t want visitors to the local National Park booking up all the emergency vehicles in town.\n\n\n\n\n\n\nFigure 2: 2021 report on NPS economic impact // Graphic by NPS\n\n\n\nThe visitation data also helps the NPS estimate the beneficial impact—economic and otherwise—that the parks have on nearby communities and the nation at large (Figure 2). These estimations are important because they help the parks advocate for more funding, support, and attention.\nThe data is also frequently reported on by journalists, who use it to highlight the most popular parks and noteworthy visitation records, as well as to point their readers to parks where they might be able to find some peace and quiet (see articles in Thrillist, Smithsonian, and CNN)."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#whats-in-the-data-what-counts-as-a-visit",
    "href": "posts/np-data/with-tabs.html#whats-in-the-data-what-counts-as-a-visit",
    "title": "U.S. National Park Visit Data",
    "section": "What’s in the data? What “counts” as a visit?",
    "text": "What’s in the data? What “counts” as a visit?\nNow that we know how the data is used, let’s dive into the data itself. What’s actually in this dataset, and what “counts” as a visit?\nTo get started, let’s load the dataset and examine a random sample of rows.\n\n\nCode\n# https://statsandr.com/blog/an-efficient-way-to-install-and-load-r-packages/\n\n# Load the dplyr package\nlibrary(dplyr, warn = FALSE)\n\n# Load National Park Visitation data\nnp_data &lt;- read.csv(\"https://github.com/melaniewalsh/responsible-datasets-in-context/raw/main/datasets/national-parks/US-National-Parks_RecreationVisits_1979-2023.csv\", stringsAsFactors = FALSE)\n\n## Look at the structure of the dataset, randomly sample 10 rows\nnp_data %&gt;% slice_sample(n = 10)\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nEverglades NP\nSoutheast\nFL\n2017\n1018557\n\n\nVoyageurs NP\nMidwest\nMN\n1987\n201727\n\n\nSaguaro NP\nIntermountain\nAZ\n1987\n689933\n\n\nCuyahoga Valley NP\nMidwest\nOH\n1996\n3455878\n\n\nCuyahoga Valley NP\nMidwest\nOH\n1980\n563300\n\n\nDenali NP & PRES\nAlaska\nAK\n1993\n505565\n\n\nChannel Islands NP\nPacific West\nCA\n2021\n319252\n\n\nCarlsbad Caverns NP\nIntermountain\nNM\n2007\n409560\n\n\nRocky Mountain NP\nIntermountain\nCO\n2018\n4590493\n\n\nRocky Mountain NP\nIntermountain\nCO\n1998\n3035422\n\n\n\n\n\n\nHere we see five columns – “ParkName”, “Region”, “State”, “Year”, and “RecreationVisits.” The first four are pretty self-explanatory, but why is the fifth labelled “RecreationVisits” rather than “Visits” or “Visitors”?\nIt turns out that the NPS distinguishes between kinds of visits to their parks. There are “recreation” visits — when people are visiting the parks for fun, vacation, exercise, etc. — and there are “non-recreation” visits — when people are visiting the parks for other reasons. For example, some people need to travel through the parks, either because a highway runs through the park, or because they live on “inholdings” (private property that is surrounded by a National Park on all sides). Other people are visiting the parks because they have actual business to conduct in the parks.\nHere’s a full list of “reportable non-recreation” visitsaccording to the NPS:\n\n\nPersons going to and from inholdings across significant parts of park land;\nCommuter and other traffic using NPS-administered roads or waterways through a park for their convenience;\nTrades-people with business in the park;\nAny civilian activity a part of or incidental to the pursuit of a gainful occupation (e.g., guides);\nGovernment personnel (other than NPS employees) with business in the park;\nCitizens using NPS buildings for civic or local government business, or attending public hearings;\nOutside research activities (visits and overnights) if independent of NPS legislated interests (e.g. meteorological research).\n\n\nWhat this means is that “recreation visit” counts leave out a lot of people. This is worth thinking about when we evaluate what the numbers mean, and how the NPS achieves them (which we’ll discuss more below).\nIt also means that they’re not counting individual people. This data doesn’t tell us anything about the people who are visiting.\n(Note: The Pine Ridge Indian Reservation in South Dakota is located inside Badlands National Park (the visitor center is on the reservation), which could be worth discussing here.)"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#data-and-data-collection",
    "href": "posts/np-data/with-tabs.html#data-and-data-collection",
    "title": "U.S. National Park Visitation Data",
    "section": "Data and data collection",
    "text": "Data and data collection\nSo now we know what is being collected. But let’s try to understand how it’s being collected. We can do this, in part, by exploring and visualising the data.\nFor example: let’s visualise the visits to Crater Lakes National Park, from 1979 to the present:\n\n\nCode\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette &lt;- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Crater Lake National Park\ncrater_lake &lt;- np_data %&gt;% filter(ParkName == \"Crater Lake NP\")\n\n# Visualize it\nggplot(data = crater_lake) + \n  geom_line(aes(x = \n  Year, y = RecreationVisits), \n  color = cb_palette[1]) +\n  labs(title = \"Crater Lake National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nWe see a lot of things in this data - not least of which is a tremendous rise in visitors in the 2010s - but one interesting observation is the sudden drop in visits in 2012. This isn’t caused by fewer people visiting: instead, it has more to do with how visitor numbers are counted.\nWhen it comes to counting visitors, the NPS uses a variety of techniques. At some parks, such as Alcatraz, it is simple: the park is only accessible via (ticketed) boat, and so NPS staff simply count the number of tickets. But other parks may have multiple entrances, and feature visitors arriving via car, bus, or on foot. It quickly becomes impractical to have staff at every entrance, 24 hours a day, just in case someone arrives.\nInstead, the NPS uses a variety of techniques - some automated, some manual. These include:\n\nInduction loop counters - magnetised coils of wire under the road that “trip” when a vehicle passes over them;\nTraffic counters, which manually increment a counter when a vehicle passes through a gate;\nExtracting data from ticketing machines.\n\n\n\n\nAn example of an induction loop installed under a road\n\n\nAlongside all of that, NPS rangers do, on many occasions, manually count people who arrive - particularly when one of the usual mechanisms doesn’t count. And that’s exactly what happened here; according to the NPS data logs, the induction loop counter at one of the main entrances simply broke in January, and wasn’t repaired for (at a minimum) several months. You can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears visits entirely tail off in 2020, as a result of the traffic counter being broken for years:\n\n\nCode\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data &lt;- np_data %&gt;% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#exercise-thinking-about-where-and-how-and-why-mechanisms-are-likely-to-break",
    "href": "posts/np-data/with-tabs.html#exercise-thinking-about-where-and-how-and-why-mechanisms-are-likely-to-break",
    "title": "U.S. National Park Visit Data",
    "section": "Exercise: thinking about where (and how, and why) mechanisms are likely to break",
    "text": "Exercise: thinking about where (and how, and why) mechanisms are likely to break\nNow that we’ve talked about how data is collected (and the fragility of some of those methods), it’s a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see Exercise 1."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#data-and-reality",
    "href": "posts/np-data/with-tabs.html#data-and-reality",
    "title": "U.S. National Park Visit Data",
    "section": "Data and reality",
    "text": "Data and reality\nChanges in data don’t only stem from changes in data collection, but also the underlying reality of what is being measured. Let’s take a look at the visitor data from Kobuk Valley National Park:\n\n\nCode\n# Filter down to Kobuk Valley National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[3]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nMost people’s eyes will immediately be drawn to the drastic drop in 2014-15, and for good reason! But the cause is familiar: it’s about data collection. As the park report notes, ” The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.“.\nBut another question would be: why the drop-off in 2018-19? It’s too early for the cause to be COVID. Instead, the cause is administrative; government shut-downs in that era led to a reduction of funding, and correspondingly the closure of various attractions at the park. The result: a lack of funding leads to a reduced visitor count - a visitor count that is often used, remember, to argue for funding. This highlights one of the ways in which seemingly-descriptive data used to make decisions can represent the state of those decisions, more than some natural “baseline”.\nAnother kind of issue of “representing reality” can be found if we look at the visitor data for Mount Rainier:\n\n\nCode\n# Filter down to Mount Rainier National Park\nrainier_data &lt;- np_data %&gt;% filter(ParkName == \"Mount Rainier NP\")\n\n# Visualise it\nggplot(data = rainier_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[4]) +\n  labs(title = \"Mount Rainier National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nOnce again, we see both a COVID-19 dropoff - but also a continued dropoff beyond that. Looking at the visitation comments explains why: flooding, fires and a blizzard drastically impeded the ability of people to get to the park, and the possibility of areas of the park opening at all."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#data-compensating",
    "href": "posts/np-data/with-tabs.html#data-compensating",
    "title": "U.S. National Park Visit Data",
    "section": "Compensating for data",
    "text": "Compensating for data\nAs all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of any data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\nSometimes this leads to odd-looking decisions."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#data-decisions",
    "href": "posts/np-data/with-tabs.html#data-decisions",
    "title": "U.S. National Park Visit Data",
    "section": "Data decisions",
    "text": "Data decisions\nAs well as multiplying up, there’s also counting down: some parks register “zero” as the number of visitors they attracted in a year:\n\n\nCode\n# Filter down to just zeros\nzero_data &lt;- np_data %&gt;% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\n\n\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has “zero counts”, Kobuk Valley National park, we see it’s hardly overrun with people even when the count isn’t zero:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nIf we look at the visitation comments again, what we see is that “The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” Which is entirely reasonable, in isolation: but we’ve also seen a lot of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#exercise-data-decisions",
    "href": "posts/np-data/with-tabs.html#exercise-data-decisions",
    "title": "U.S. National Park Visit Data",
    "section": "Exercise: data decisions",
    "text": "Exercise: data decisions\nReader note: in this exercise, users will try to use public data - twitter posts, flickr photos, etc, etc - to try and find situations where people are identifying themselves as being at a park that, officially, has 0 people present at that time Have them go through public data and try to find proof the counts of 0 are “wrong”"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#exercise-1",
    "href": "posts/np-data/with-tabs.html#exercise-1",
    "title": "U.S. National Park Visit Data",
    "section": "Activity 1",
    "text": "Activity 1\nIt is inevitable that the devices that the National Park Service uses to count visits to the parks — like induction loop counters installed on the road — will break. But they will also get fixed at different rates, in different locations, as we could see in the case of Crater Lake National Park (where a counter was fixed quickly) and Carlsbad Caverns National Park (where a broken counter from 2019 still has not been fixed).\nThere are many reasons for these disparities, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it. The less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritized by the repair teams that can be dispatched.\nWith this in mind, look at the locations of the following parks. Suppose that each one has an outage in their induction loop counter: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n\n\nPark\nPriority (1-5)\nReason\n\n\n\n\nAcadia NP\n\n\n\n\nLassen Volcanic NP\n\n\n\n\nSaguaro NP\n\n\n\n\nYosemite NP\n\n\n\n\nMammoth Cave NP"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#exercise-2",
    "href": "posts/np-data/with-tabs.html#exercise-2",
    "title": "U.S. National Park Visit Data",
    "section": "Activity 2",
    "text": "Activity 2\nThe National Park Service sometimes fills in missing data with hard numbers or approximates data by applying special mathematical formulas. This is necessary work, but it is also under-explained work.\nTo see this in action, go to the NPS page that documents park reports and down the “Visitor Use Counting Procedures” PDF for three different parks.\nHow are the procedures for these three parks similar or different? What kind of effect do you think this has on the resulting data? What do you think is the best of documenting this information and communicating it to users of the data?"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#national-park-visits-recreation-1979-2023",
    "href": "posts/np-data/with-tabs.html#national-park-visits-recreation-1979-2023",
    "title": "National Park Visitation Data",
    "section": "National Park Visits (Recreation) — 1979-2023",
    "text": "National Park Visits (Recreation) — 1979-2023\n\n\nCode\nviewof search = Inputs.search(data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#national-park-visits-1979-2023",
    "href": "posts/np-data/with-tabs.html#national-park-visits-1979-2023",
    "title": "National Park Visitation Data",
    "section": "National Park Visits — 1979-2023",
    "text": "National Park Visits — 1979-2023\n\n\nCode\nviewof search = Inputs.search(visit_data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#national-park-use-by-month-1979-2023",
    "href": "posts/np-data/with-tabs.html#national-park-use-by-month-1979-2023",
    "title": "National Park Visitation Data",
    "section": "National Park Use By Month — 1979-2023",
    "text": "National Park Use By Month — 1979-2023\n\n\nCode\nviewof use_search = Inputs.search(use_data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(use_search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#u.s.-national-park-visits-1979-2023",
    "href": "posts/np-data/with-tabs.html#u.s.-national-park-visits-1979-2023",
    "title": "U.S. National Park Visit Data",
    "section": "U.S. National Park Visits — 1979-2023",
    "text": "U.S. National Park Visits — 1979-2023\n\n\nCode\nviewof search = Inputs.search(visit_data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#u.s.-national-park-use-monthly-1979-2023",
    "href": "posts/np-data/with-tabs.html#u.s.-national-park-use-monthly-1979-2023",
    "title": "U.S. National Park Visit Data",
    "section": "U.S. National Park Use (Monthly) — 1979-2023",
    "text": "U.S. National Park Use (Monthly) — 1979-2023\n\n\nCode\nviewof use_search = Inputs.search(use_data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(use_search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#how-was-the-data-collected",
    "href": "posts/np-data/with-tabs.html#how-was-the-data-collected",
    "title": "U.S. National Park Visit Data",
    "section": "How was the data collected?",
    "text": "How was the data collected?\nSo how does the NPS actually count these recreation visits? Take a moment and see if you come up with a few guesses…\nIt turns out that each park counts visits differently. And at many parks, each entrance at each park even counts visits differently.\nIf you go to the “Park Reports” tab in the NPS Data Portal, you can look up an individual park and download a PDF file called “Visitor Use Counting Procedures,” which details exactly what procedures they use to count visits at this park. Most of the parks have several PDFs because their counting procedures have changed many times over the years!\nTo count visits, most parks use a combination of automatic traffic counters and manual counting—that is, staff members who use their eyeballs to literally count the number of people arriving by foot, bike, bus, cross-country skis, snowmobile, boat, canoe, etc. Perhaps most interesting, they usually take those counts and then apply a specifically designed mathematical formula to arrive at the most accurate estimate of number of recreation visits — adding, subtracting, and multiplying the counts based on a variety of factors, such as the season or the entrance (e.g. assuming that more people would likely be arriving in a car in the summer months at the most popular gate than in the winter months at the least popular gate) or how many non-recreation visits they expect are a confounding factor.\nThis browser does not support PDFs. Please download the PDF to view it: &lt;a href=\"Everglades_Visitor-Use-Counting-Procedures_2023.pdf\"&gt;Download PDF&lt;/a&gt;\nFor example, at Everglades National Park, at the Shark Valley Entrance, there is a pneumatic tube traffic counter that counts the number of cars that pass over it. The staff members then apply different mathematical operations to this number in order to arrive at what they think is the most accurate estimate of recreation visits:\n\nThe traffic count is divided by 2 to account for entry and exit. The adjusted traffic count is reduced by the number of buses, the number of bicycles counted when the entrance station is open, 127 bicycles per month to account for after-hours use, and by 200 non-recreation vehicles per month October through May and 100 non-recreation vehicles per month June through September. The traffic count is further reduced by 350 non-reportable (NPS) vehicles per month. The reduced count is multiplied by 2.17 persons per vehicle.\n\nWhat’s more, the devices that the NPS uses to count visits, like pneumatic tube counters or induction loop counters (magnetised coils of wire that are installed under a road, and that “trip” when a vehicle passes over them) sometimes break.\n\n\n\nAn example of a pneumatic tube traffic counter, installed above the road\n\n\n\n\n\nAn example of an induction loop, installed beneath a road (making it harder to detect when it breaks!)\n\n\nFor example, according to the NPS data logs, the induction loop counter at one of the main entrances at Crater Lakes National Park broke in 2012 and wasn’t repaired for at least a year:\n\n2/1/2012 | The Traffic Counter at Annie Springs Entrance Station was not functioning properly and therefore we have a count of zero.\n\n\n3/1/2012 | Broken counter at Annie Springs Entrance, unable to record numbers.\n\n\n4/1/2012 | Traffic counter was broken for the beginning of the month and may have low numbers.\n\n\n10/1/2012 | Counts estimated by Butch\n\n\n11/1/2012 | TRAFFIC COUNT AT ANNIE SPRINGS ENTRANCE NOT AVAILIBLE\n\n\n12/1/2012 | TRAFFIC COUNT AT ANNIE SPRINGS ENTRANCE NOT AVAILIBLE\n\n\n1/1/2013 | Traffic count at Annie Springs estimated.\n\n\n2/1/2013 | Traffic count at Annie Springs estimated.\n\nYou can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears that visits have been declining since around 2019:\n\n\nCode\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette &lt;- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data &lt;- np_data %&gt;% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nThis decline may, in part, be due to the COVID-19 pandemic.\nBut the NPS logs also show that the main induction loop counter at Carlsbad Caverns broke in 2019 and has remained broken for multiple years:\n\n9/1/2019 | Traffic counter apparently has been broken since July. Traffic counts are estimated.\n\n\n4/1/2020 | Main road traffic counter is broken, I have estimated the count.\n\n\n12/1/2020 | Corona virus closure that began in November ended on December 4th. Main road traffic counter remains broken.Possible problem with Loop Road counter.\n\n\n4/1/2022 Main road traffic counter remains broken. Rattlesnake Springs traffic counter seems to be off, I will henceforth provide estimates.\n\n\n9/1/2023 | Loop Road and backcountry closed due to flood damage. Slaughter Canyon Cave remains closed Traffic counter on main road remains broken.\n\n\n\n\n\n\n\nActivity 1\n\n\n\nNow that we’ve talked about how data is collected (and the fragility of some of those methods), it’s a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see Activity 1."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#activity-3",
    "href": "posts/np-data/with-tabs.html#activity-3",
    "title": "U.S. National Park Visit Data",
    "section": "Activity 3",
    "text": "Activity 3\nIn 2014 and 2015, Kobuk Valley National Park reported that there were zero visitors to the park.\nUse publicly available internet data - Twitter posts, Flickr photos, etc - to try and find evidence of people visiting the park (there is existing evidence!).\nBased on your findings, how do you think, differently, if at all, about Kobuk Valley’s decision to record zero visits and about alternative methods for counting visits?"
  },
  {
    "objectID": "posts/np-data/with-tabs.html#what-data-is-missing-how-is-uncertainty-handled",
    "href": "posts/np-data/with-tabs.html#what-data-is-missing-how-is-uncertainty-handled",
    "title": "U.S. National Park Visit Data",
    "section": "What data is missing? How is uncertainty handled?",
    "text": "What data is missing? How is uncertainty handled?\nIf you filter the data and examine the least visited National Parks across these many decades, you’ll notice that there are some parks that had zero visitors in a given year.\n\n\nCode\n# Filter for minimum RecVisits\nleast_visited &lt;- np_data %&gt;% filter(RecreationVisits == min(RecreationVisits))\n\n# Show some of them\nleast_visited  %&gt;% slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\n\n\n\n\nYou might guess that there are no visits in these years because these parks are all located in remote places that are hard to get to, like rural Alaska or American Samoa.\nIf we look at the visitation trends for Kobuk Valley National Park, for example, we can see that a couple of years with zero visits isn’t a huge aberration:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nBut it turns out that in 2014 and 2015, Kobuk Valley National Park actually didn’t count visitors at all.\nIf we look at the visitation reports for Kobuk Valley in 2014, they say that “the park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” But even though they didn’t count visitors at all, they still recorded a zero in those two years. This hard number makes it seem conclusive, like there really were zero people people who stepped onto the park lands in those years.\nIn 2015, John Quinley, the Alaska regional spokesperson for the NPS, spoke with the Anchorage Daily News about this issue, and he admitted that “it might have been better if park statisticians had put something other than a zero in the visitor box for 2014 — say maybe a question mark.”\n\n\n\n\n\n\nDiscussion\n\n\n\nWhy would you or wouldn’t you want to record a question mark in this dataset? What else could you use to record uncertainty?\n\n\nThe decision not to record visits in certain years seems reasonable on its face, but we’ve also seen a lot of parks in more highly-frequented areas that, when faced with a similar situation, chose to provide an estimate for a certain year based on average counts from previous years, rather than simply declare that nobody visited. This matters because, as we’ve discussed, there are financial, political, and social ramifications of these visit count numbers."
  },
  {
    "objectID": "posts/np-data/with-tabs.html#conclucion",
    "href": "posts/np-data/with-tabs.html#conclucion",
    "title": "U.S. National Park Visit Data",
    "section": "Conclucion",
    "text": "Conclucion\nTo-do"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#introduction",
    "href": "posts/top-500-novels/top-500-novels.html#introduction",
    "title": "Library Top 500",
    "section": "Introduction",
    "text": "Introduction\nThis dataset contains information on the top 500 novels most widely held in libraries, according to OCLC, a global library organization with over 16,000 member libraries in over 100 countries. The dataset includes information on authors’ biographies, library holdings, and online engagement for each novel, as well as the full text for all works that are not currently under copyright (190 novels).\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data  \nThis dataset is based on a list of the Top 500 Novels compiled by OCLC from information in their online database WorldCat, the largest database of library records. The first section of the list was published online with great fanfare as the Library Top 100 in 2019, accompanied by the claim that for novels, “literary greatness can be measured by how many libraries have a copy on their shelves.”\nWe wondered about the implications of this claim and more broadly about what it means to base ideas of “literary greatness” on the number of libraries that hold a particular work. How do historical biases in systems of literary production, preservation, and circulation figure into these kinds of claims? And how do we even define what counts as a novel?\nTo contextualize the initial list and dig into its claims about literary greatness, we collected information on each novel from a number of other databases, including Wikipedia, Goodreads, Project Gutenberg, the Virtual International Authority File (VIAF), and Classify (a now-shuttered OCLC tool), which we have compiled here.\nThe dataset was created by Anna Preus and Aashna Sheth, who are also the authors of this data essay."
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#history",
    "href": "posts/top-500-novels/top-500-novels.html#history",
    "title": "Library Top 500",
    "section": "HISTORY",
    "text": "HISTORY\nTo start, what is a novel? Today, novels are so prevalent that the term is often applied to a much wider range of books than it actually describes. “Novel” is an umbrella term that applies to works of longform fiction in a range of genres: romance, sci-fi, historical fiction, horror, detective fiction, westerns, etc. The term generally does not apply– although these distinctions can sometimes be fuzzy–to short fiction, poetry, plays, biographies, or other non-fiction forms. The term novel was first used to describe a “long fictional prose narrative” in the 1600s, and the form increased in popularity across the eighteenth and nineteenth centuries. Interestingly, OCLC’s list of top 500 novels extends much further back than this. The oldest work on the list is The Tale of Genji, a classic work of Japanese literature written over 1,000 years ago.\nA key issue in literary studies is which books from the past we continue to read in the present, and which books from the present we will continue to read in the future. The vast majority of novels fall out of circulation shortly after they are published, quickly becoming part of what Margaret Cohen has called “the great unread.” When teachers assign texts in their classes and when literary scholars conduct research, they’re making choices about which texts continue to be valuable and important for people to read and study.\nThe term “canon” in literary studies refers to texts that continue to be considered important over time. Ankhi Mukherjee defines the canon as “a set of texts whose value and readability have borne the test of time” and notes that it “ involves not merely a work’s admission into an elite club, but its induction into ongoing critical dialogue and contestations of literary value.” Canonical works continue to be read, taught, and discussed, and in popular terminology they’re often considered “classics.” These are works you might read in a high school English class: F. Scott Fitzgerald’s _The Great Gatsby, _for example, or Harper Lee’s To Kill a Mockingbird. \nOne of the things that defines a classic is the fact that it stays in print for a long period of time. When a print book is published, it is issued in an edition with a specific number of physical copies. If the book is profitable, it may be re-issued in different editions over many years. If it becomes a classic, it is likely to be issued in dozens or hundreds of editions even long after the author’s death.\nIn addition to classics, libraries are invested in making popular new novels available to readers. The Top 500 list includes many recently published best-sellers, including books in the Harry Potter, Twilight, and Hunger Games series. Some of these popular books go on to become classics–Charles Dickens’s Great Expectations, which was wildly successful in its day, is a good example. Many popular texts, though, do not become canonical.\nBy focusing on the books that librarians around the world have chosen to continue to make available to readers, OCLC was able to create a list of widely read novels that includes both classic works and more recent, popular works that may not have received the same levels of literary acclaim. This represents a unique opportunity to look at….\nWe wondered, though, how did OCLC’s data compare to other potential indicators of popularity or canonicity? And, for that matter, how was the list actually constructed?"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#where-did-the-data-come-from-who-collected-it",
    "href": "posts/top-500-novels/top-500-novels.html#where-did-the-data-come-from-who-collected-it",
    "title": "Library Top 500",
    "section": "WHERE DID THE DATA COME FROM? WHO COLLECTED IT?",
    "text": "WHERE DID THE DATA COME FROM? WHO COLLECTED IT?\nThe initial list of Top 500 novels was collected by a team at OCLC, the non-profit organization that manages WorldCat. It was compiled based on analysis of data in WorldCat, which consists of catalog records created by librarians around the world, and entered into WorldCat.\nBuilding on this list, we compiled data from a number of other databases, including Project Gutenberg, VIAF, and Wikipedia–a process that is described in greater detail below."
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#why-was-the-data-collected-how-is-the-data-used",
    "href": "posts/top-500-novels/top-500-novels.html#why-was-the-data-collected-how-is-the-data-used",
    "title": "Library Top 500",
    "section": "WHY WAS THE DATA COLLECTED? HOW IS THE DATA USED?",
    "text": "WHY WAS THE DATA COLLECTED? HOW IS THE DATA USED?\nOCLC’s goal in producing the Top 500 list seems to be to encourage library patronage and reading. The website for the list includes a “Librarians Kit” with a variety of publicity materials–from printable bookmarks to Instagram tiles-that can help bring attention to books in the Top 500 list within libraries’ collections.\nNeed to link to local image file or to image URL ![alt_text](images/image1.png \"image_tooltip\")\nOur goal was to collect additional data to understand better how the list was constructed, and to contextualize and nuance its claims about literary greatness."
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#whats-in-the-data-what-makes-a-book-a-top-novel",
    "href": "posts/top-500-novels/top-500-novels.html#whats-in-the-data-what-makes-a-book-a-top-novel",
    "title": "Library Top 500",
    "section": "WHAT’S IN THE DATA? WHAT MAKES A BOOK A “TOP NOVEL”?",
    "text": "WHAT’S IN THE DATA? WHAT MAKES A BOOK A “TOP NOVEL”?\nThe Top 500 list represents a massive data extraction and analysis effort on the part of OCLC. While they do not provide detailed information on how the list was compiled, they do offer a brief explanation of the process that went into creating the list on their FAQ page (written in the context of the top 100, but also applies to the top 500):\n\nMaterials in libraries are described and tracked in WorldCat in two ways. Any specific work of literature, music, art, history, etc., has an associated catalog record. This describes the item in a general sense. Every copy of the same book, for example, shares the same record. WorldCat also tracks library holdings, which indicate that a specific library has (or holds) at least one copy of that item.\n\n&gt; The Library 100 is based on the total number of holdings for a specific novel across all libraries that have registered that information in WorldCat. When a library tells OCLC, “We have a copy of that book available,” that counts as a holding, and in the case of The Library 100, counts as +1 toward its ranking on the list.\nThis process initially sounds straightforward: to create the Top 500 list, the OCLC team presumably searched the title of a work, counted the number of libraries that held each title, and published the first 500. But it turns out it’s actually much more complicated than that. In WorldCat, records are stored by edition, meaning that each edition has its own catalog record, and an individual title like, say, Miguel de Cervantes’s Don Quixote, may have been released in hundreds or thousands of editions since its initial publication. In the U.S., the most common format for digital library records is MARC, which stands for MAchine Readable Cataloging. Librarians with specialized training create detailed MARC records for each edition of a book, and librarians at public libraries, academic libraries, cultural heritage institutions, and private collections tag individual copies of the book that their library holds to that record.\nThis means that when developing the list, the OCLC team actually had to find all the editions of a specific title and sum the number of libraries that hold that edition across all editions. Thus the top 500 list is not only a representation of how many libraries carry the work, but a representation of how many times a book has been re-edited and re-issued; the more editions a book has, the more records are created. Often, there are duplicate records for individual editions, which may affect the overall count of copies tallied by the OCLC. And when a work is translated into different languages, all the editions of all the translations are also recorded in WorldCat, which also figures into the count of total holdings for each novel."
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#how-was-the-data-collected-what-additional-data-was-added",
    "href": "posts/top-500-novels/top-500-novels.html#how-was-the-data-collected-what-additional-data-was-added",
    "title": "Library Top 500",
    "section": "HOW WAS THE DATA COLLECTED? WHAT ADDITIONAL DATA WAS ADDED?",
    "text": "HOW WAS THE DATA COLLECTED? WHAT ADDITIONAL DATA WAS ADDED?\nWe wanted to contextualize the Library Top 500 list by compiling additional information on each novel from a range of other sources. We focused on gathering three main categories of information: information that could help us understand what types of works–and whose works–were included on the list, data that could potentially provide alternate measures of popularity or canonicity, and the full text of each novel that was in the public domain. We collected information from the following sources:\nWorldCat: we used the now-shuttered OCLC tool Classify to gather data from WorldCat on the top 100 most widely held editions of each of the 500 novels on the list. We recorded total library holdings for these top 100 editions. We consider number of editions as a potential alternate measure of canonicity, although it is necessarily affected by the amount of time that has passed since the initial publication of the novel.\nVIAF: The Virtual International Authority File is an OCLC-run database that contains structured records–called “name authority files”–for individual authors and creators. We used VIAF to gather information on authors whose novels were included on the list, including their birth and death dates, nationalities, genders, and occupations.\nNeed to link to local image file or to image URL ![alt_text](images/image2.png \"image_tooltip\")\nWikipedia: we used Wikipedia, the popular, free, volunteer-authored encyclopedia, to identify the year of first publication for each novel on the list.\nGoodreads: Goodreads, which is owned by Amazon, is the largest social networking site related to books, with over 150 million members. Itt allows users to rate, review, and discuss a huge range of texts. We drew on data from Goodreads as a potential alternate indicator of texts’ popularity, collecting total number of reviews, total number of ratings, and average overall rating for each novel on the list.\nProject Gutenberg: We used Project Gutenberg to access the full-text of all novels on the list that are currently in the public domain, or in other words, out of copyright. We chose Project Gutenberg because their eBooks are edited by volunteers, whereas many larger content repositories, like Internet Archive and HathiTrust, only make available machine-generated transcriptions of historical texts, which tend to be less accurate.\nOur work creating this dataset not only builds on the work of the OCLC team who compiled the Top 500 list, but on the labor of the thousands of librarians who created records held in WorldCat and VIAF, of the volunteers who transcribed texts for Project Gutenberg and wrote articles for Wikipedia, and of the social media users who reviewed and rated books on Goodreads."
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#acknowledging-bias-metadata-analysis",
    "href": "posts/top-500-novels/top-500-novels.html#acknowledging-bias-metadata-analysis",
    "title": "Library Top 500",
    "section": "ACKNOWLEDGING BIAS [METADATA ANALYSIS?]",
    "text": "ACKNOWLEDGING BIAS [METADATA ANALYSIS?]\nThe Top 500 List provides an unprecedented opportunity to consider what works libraries around the world have on their shelves. This, in turn, serves as an important indicator of books’ continued relevance to readers. As OCLC points out, “libraries offer access to trendy and popular books. But, they don’t keep them on the shelf if they’re not repeatedly requested by their communities over the years.” Looking at what novels are held by the most libraries provides a sense of which works librarians consider important to continue to make available to readers.\nAt the same time, there are distinct biases in what gets kept on library shelves, and in which library shelves are being considered. The libraries that OCLC works with are disproportionately located in Europe and North America and OCLC uses cataloging systems developed in English-language contexts. The list is distinctly skewed toward works by White, European and American men, as is English literary history, but it would be impossible[difficult?] to tease apart this historical bias from potential compounding biases in WorldCat’s underlying data, the data collection process, or library cataloging systems more broadly.\nOCLC acknowledges broad biases in the list in a section titled, “Why isn’t the list more diverse?”writing, “The list emphasizes many books that we tend to think of as ‘classics,’ because those are the novels most often translated, retold in different editions, taught and widely distributed in library collections. Because of this, the list tends to reflect more dominant cultural views.” Although OCLC acknowledges this general bias towards works considered classics, more specific forms of bias aren’t made apparent in the list itself, which only includes the title and author for each novel.\nNeed to link to local image file or to image URL ![alt_text](images/image3.png \"image_tooltip\")\nEach of these works and authors, of course, deserves careful consideration in their own right, but by compiling additional information into dataset, we can begin to see some of these biases as well as trends across the list more clearly.\n[ Metadata analysis prompts?\nOver 85% of the novels on the top 500 list were originally published in English\nOver 80% were written by authors from the U.S. or Great Britain\nOver 70% were written by men]\nWe collected this data because we were interested in contextualizing the top 500 list. The top 500 list itself was compiled because… It is used….. We hope that our dataset will be used like…\n\nReinforces what books are read (people pay more attention to the books that are labeled as “top 500”), could overshadow other important books\nOCLC put out this list to encourage publicity / reading. Wasn’t made for academics to use!"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#whats-in-the-data-what-makes-a-book-a-top-novel-metadata-analysis",
    "href": "posts/top-500-novels/top-500-novels.html#whats-in-the-data-what-makes-a-book-a-top-novel-metadata-analysis",
    "title": "Library Top 500",
    "section": "WHAT’S IN THE DATA? WHAT MAKES A BOOK A “TOP NOVEL”? [Metadata Analysis?]",
    "text": "WHAT’S IN THE DATA? WHAT MAKES A BOOK A “TOP NOVEL”? [Metadata Analysis?]\nBy building on OCLC’s initial list and adding a range of information from other databases, we wanted to create a dataset that would offer opportunities to connect metadata analysis and full-text analysis in relation to a historically significant corpus of texts. To this end, we’ve included a brief exploration of the data below, as well as suggested activities, and some ideas for future areas of inquiry.\nFor starters, let’s look into some author metadata. Who is represented in the most popular works and what may this reveal about literary canonization?\n\nAuthor Gender\nWhich author names are most represented\nAuthor Map\nNumber of books in each time period (buckets for 1800-1900, 1900-2000, etc).\nRank vs number of editions\nAuthor languages/language of books?\n\n\n\n\n\n\n\nActivity 1\n\n\n\n&lt;**Activity** about looking into what “unnamed gender” may mean and discussion about power of labels?&gt; For more, see [Activity 1](#exercise-1).\n\n\nFrom our initial metadata analysis, we find that canonized works are those that are (1) written by white men, (2) primarily between 1900-2000, (3) primarily of x genre, and (4) have at least x editions.\nLet’s take a look at how OCLC books stack up against GoodReads rankings.\nActivity about whether num_ratings or average_rating would be better to use. What factors affect them?&gt;\nWe decide to use num_ratings as a fair comparison against OCLC num_libraries. Do the number of copies really match the number of people that check it out and read it, at least according to goodreads?\n\nLook at top 5 goodreads num_ratings vs top 5 oclc\nStock chart of books that moved up and down\n\nActivity: Which books had the most movement? Which had the least? Are there any trends?&gt;\n*ebook vs on shelf, translations into english or other languages\nNow that we’ve explored questions of representation and popularity, let’s dive into some full text analysis.\nTHIS IS VERY TBD"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#conclusion",
    "href": "posts/top-500-novels/top-500-novels.html#conclusion",
    "title": "Library Top 500",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nText text.\n\nGoodreads data is skewed towards younger users (average goodreads demographic), and people who actually rate (also younger people)\nRelating goodreads num ratings is similar to how many libraries… how many libraries is inadvertently trying to measure, how many people read it ?\n\n“How many libraries have the book on their shelves”\nBut there is a gap between publishing proliferation (canonization) and true popularity (people reading it).\nhttps://www.tckpublishing.com/the-literary-canon/\n\n\nQUESTIONS:\n\nFighting words\nGenres\nActivities in laid with data essay? What do we wanna have as exercise and what in metadata analysis?\n\nPossible activities:\n\nLet’s plot gender information, we see this 3rd category, what do you think it represents?\n\nRefer back to data, look up the history of a couple authors tagged with this? Make a point about how labels are important to provide context and can also be diminishing/obscuring/normative\n\nGoodreads:\n\nWhat factors affect popularity on goodreads? Why do you think the top5 books are so different?\nWho liked vs number of ratings? What’s the difference? What’s fair to compare with OCLC?\nWhich books had the largest change in ranking? What do you think this means?\nIncorporating voyant\n\n\nCut from history section:\nLibraries keep records of the works they hold in their collections, and they create and organize these records in accordance with particular cataloging systems. Historically, these catalogs have been drawers of physical cards containing information about each book.\n\n&gt;&gt;&gt;&gt;&gt; gd2md-html alert: inline image link here (to images/image4.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; \n\nNeed to link to local image file or to image URL ![alt_text](images/image4.png \"image_tooltip\")\n\n&gt;&gt;&gt;&gt;&gt; gd2md-html alert: inline image link here (to images/image5.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; \n\nNeed to link to local image file or to image URL ![alt_text](images/image5.png \"image_tooltip\")\nWhen data storage on computers became powerful and popular in the mid-to-late 1900s, these cards were re-written to meet the MAchine Readable Cataloging (MARC) format. This format made it easier to digitize and standardize physical cards. Once a book’s MARC record was online, libraries could print and distribute the same card.\nLater on, as libraries gained personal computers, the physical cards themselves became obsolete and patrons could search an online database for book information. The contents of the LOC’s MARC record database are the foundation of modern library browsing systems. The contents of the MARC record help populate a webpage about each book. Nowadays, more information is added to these webpages like reviews, star-ratings, and even some digitized pages.\nAlthough each library or library system usually has its own browsing website, there are key central entities that contain information from many libraries. The current largest global database of library information is called WorldCat, which is maintained by OCLC and allows for searching across 2.7 billion records from libraries in over 100 countries."
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#library-top-500",
    "href": "posts/top-500-novels/top-500-novels.html#library-top-500",
    "title": "Library Top 500",
    "section": "Library Top 500",
    "text": "Library Top 500\n\n\nCode\nviewof search = Inputs.search(visit_data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#u.s.-national-park-use-monthly-1979-2023",
    "href": "posts/top-500-novels/top-500-novels.html#u.s.-national-park-use-monthly-1979-2023",
    "title": "Library Top 500",
    "section": "U.S. National Park Use (Monthly) — 1979-2023",
    "text": "U.S. National Park Use (Monthly) — 1979-2023\n\n\nCode\nviewof use_search = Inputs.search(use_data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(use_search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n Download Data"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#exercise-1",
    "href": "posts/top-500-novels/top-500-novels.html#exercise-1",
    "title": "Library Top 500",
    "section": "Activity 1",
    "text": "Activity 1\nIt is inevitable that the devices that the National Park Service uses to count visits to the parks — like induction loop counters installed on the road — will break. But they will also get fixed at different rates, in different locations, as we could see in the case of Crater Lake National Park (where a counter was fixed quickly) and Carlsbad Caverns National Park (where a broken counter from 2019 still has not been fixed).\nThere are many reasons for these disparities, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it. The less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritized by the repair teams that can be dispatched.\nWith this in mind, look at the locations of the following parks. Suppose that each one has an outage in their induction loop counter: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n\n\nPark\nPriority (1-5)\nReason\n\n\n\n\nAcadia NP\n\n\n\n\nLassen Volcanic NP\n\n\n\n\nSaguaro NP\n\n\n\n\nYosemite NP\n\n\n\n\nMammoth Cave NP"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#exercise-2",
    "href": "posts/top-500-novels/top-500-novels.html#exercise-2",
    "title": "Library Top 500",
    "section": "Activity 2",
    "text": "Activity 2\nThe National Park Service sometimes fills in missing data with hard numbers or approximates data by applying special mathematical formulas. This is necessary work, but it is also under-explained work.\nTo see this in action, go to the NPS page that documents park reports and down the “Visitor Use Counting Procedures” PDF for three different parks.\nHow are the procedures for these three parks similar or different? What kind of effect do you think this has on the resulting data? What do you think is the best of documenting this information and communicating it to users of the data?"
  },
  {
    "objectID": "posts/top-500-novels/top-500-novels.html#activity-3",
    "href": "posts/top-500-novels/top-500-novels.html#activity-3",
    "title": "Library Top 500",
    "section": "Activity 3",
    "text": "Activity 3\nIn 2014 and 2015, Kobuk Valley National Park reported that there were zero visitors to the park.\nUse publicly available internet data - Twitter posts, Flickr photos, etc - to try and find evidence of people visiting the park (there is existing evidence!).\nBased on your findings, how do you think, differently, if at all, about Kobuk Valley’s decision to record zero visits and about alternative methods for counting visits?"
  },
  {
    "objectID": "posts/top-500-novels/exercises/Intro-to-DPLYR-NP.html",
    "href": "posts/top-500-novels/exercises/Intro-to-DPLYR-NP.html",
    "title": "Introduction to DPLYR with Top 500 Novels",
    "section": "",
    "text": "Download as R Script\n Solutions"
  },
  {
    "objectID": "posts/top-500-novels/exercises/Intro-to-DPLYR-NP.html#introduction-to-dplyr-with-national-park-visitation-data",
    "href": "posts/top-500-novels/exercises/Intro-to-DPLYR-NP.html#introduction-to-dplyr-with-national-park-visitation-data",
    "title": "Introduction to DPLYR with Top 500 Novels",
    "section": "",
    "text": "Download as R Script\n Solutions"
  },
  {
    "objectID": "posts/np-data/np-data.html",
    "href": "posts/np-data/np-data.html",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Data EssayExplore the DataExercisesDiscussion & Activities\n\n\n\n\nThis dataset contains the number of visits, per year, to each of the 63 National Parks administered by the United States National Park Service (NPS), from 1979 to the present. The NPS also collects visitation data for other park units, such as national battlfieds, national rivers, and national monuments. However, information about other park units is not included in this particular dataset.\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\nThis particular dataset is drawn from data published by the NPS. Most (but not all) of the contextual information included here draws from material published by the NPS, as well. However, the original data is made available in an NPS data portal that is relatively hard to find, and its documentation is scattered across many different web pages, which is why we believe it is valuable to curate and publish it in a single place here.\nThis dataset was curated and published by Melanie Walsh, and the data essay was written by Os Keyes and Melanie Walsh.\n\n\n\nThe National Park Service actually began recording information about park visits in 1904 (more than 100 years ago!). However, at this time, their visit collection methods were mostly informal, inconsistent, and low-tech. But over the next century, the NPS worked hard to make their data collection methods more reliable, consistent, and (in some but not all cases) high-tech.\nA big catalyst for the NPS getting serious about data collection was a new law. In 1965, the U.S. Congress passed a federal law that was very important for the NPS and for anybody who loves the outdoors: The Land and Water Conservation Fund Act of 1965. This act created a new source of government money specifically dedicated to protecting natural resources (i.e. to buying up land and water so that condo developers couldn’t do it first) and building up outdoor recreation infrastructure in the U.S.\nOne of the clauses in this act stipulated that the amount of money allocated to each recreation area should be “proportional to visitor use.” Because the NPS can’t function without money, they buckled down on counting visitor use. According to the NPS, over the next twenty years, they “developed and institutionalized a formal system for collecting, compiling and reporting visitor use data.”\nWhile today’s visit data collection system is far more formal and sophisticated than the one that the NPS used in 1904, there are still many inconsistencies, flaws, and limitations in this system. These shortcomings are largely unavoidable. Trying to record every single visit to a National Park — across dozens of different parks and geographic regions, many decades of time, countless different weather conditions and funding situations, and hundreds of millions of people — is pretty much impossible. In fact, one of the reasons that this dataset is so useful and illuminating is because it does a good job of communicating an important point: data can never reflect reality precisely.\nHowever, the NPS visitation data also does a good job of communicating why we might be interested in collecting and analyzing even flawed and approximate data, as we will dig into below.\n\n\n\nThis National Park visitation data was originally organized and published by the NPS Social Science Program, a specific program tasked with coordinating visitor statistics across the parks. Thousands of staff members were also involved in the data collection process for individual parks, as we will elaborate below.\nThe original data was made available through the NPS Visitor Use Statistics data portal. Through this portal, you can generate reports and download data for many different park visitation categories and time periods— at both the national and individual park levels.\nTo download the data included here, we selected the “Query Builder for Public Use Statistics (1979 - Last Calendar Year)” report type. We then selected only National Parks; all possible years (1979-2022); all possible regions; only “Recreation Visits”; the additional fields of “State” and “Region”; as well as the option of an annual summary of visit counts (as opposed to monthly visit counts). We then downloaded this report as a CSV and published it to GitHub for easier access.\n\n\n\n\nAs we’ve already discussed, one of the reasons that the NPS collects visit data is because the government basically requires it. But there are a lot of other reasons that the NPS collects this information.\nAs the NPS writes on their website, they use visit data to determine which facilities might need more or less attention, which parks might need more or less staff members and programs, and which hiking trails or bathrooms might need more or less maintenance. This information also helps the communities and businesses surrounding the parks understand how they can best share and support resources in a given area — services like emergency vehicles, sanitation, and water. If there are millions more people going on hikes in a particular area, and thus, inevitably, many more people requiring ambulance trips or rescue helicopters, that would be a very important thing for a community to know. It would be dangerous if visitors to National Parks suddenly and unexpectedly called all the emergency vehicles in town.\nThis visitation data also helps the NPS estimate the beneficial impact, economic and otherwise, that the parks have on nearby communities and the nation at large. These estimations are important because they help the parks advocate for more funding, support, attention, and collaboration.\n\nThe data can also be used for a variety of other purposes…. (such as?)\n\n\n\nIf we open the dataset and look at the first few rows, we will find five columns – “ParkName”, “Region”, “State”, “Year”, and “RecreationVisits”:\n\n\nCode\n# https://statsandr.com/blog/an-efficient-way-to-install-and-load-r-packages/\n\n# Load the dplyr package\nlibrary(dplyr, warn = FALSE)\n\n# Load National Park Visitation data\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\", stringsAsFactors = FALSE)\n\n## Look at the structure of the dataset\nnp_data %&gt;% slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nSequoia NP\nPacific West\nCA\n1996\n838060\n\n\nSaguaro NP\nIntermountain\nAZ\n1996\n671643\n\n\nHot Springs NP\nMidwest\nAR\n2003\n1561311\n\n\nPinnacles NP\nPacific West\nCA\n1999\n164854\n\n\nIsle Royale NP\nMidwest\nMI\n2016\n24966\n\n\nGreat Sand Dunes NP & PRES\nIntermountain\nCO\n2016\n388308\n\n\nYellowstone NP\nIntermountain\nWY\n1986\n2363756\n\n\nCongaree NP\nSoutheast\nSC\n1989\n25445\n\n\nGuadalupe Mountains NP\nIntermountain\nTX\n2005\n170383\n\n\nArches NP\nIntermountain\nUT\n1997\n858525\n\n\n\n\n\n\nThe first four are self-explanatory: but why is the fifth labelled “RecreationVisits” rather than “Visits”, or “Visitors”?\nThe answer is that what this dataset is tracking is more complicated and nuanced than “people who go to NPS properties”. People go to the national parks for a lot of reasons. While many are there for recreation, some travel through the parks, either because a highway runs through or because they live on “inholdings” (private property that is surrounded by a national park on all sides). Because of this, the NPS defines “Recreation Visits” as visits made by people who are not:\n\nusing park territory, roads, and facilities for their own convenience or as a part of their occupation. &gt; Reportable non-recreation visits include:\n\nPersons going to and from inholdings across significant parts of park land;\nCommuter and other traffic using NPS-administered roads or waterways through a park for their convenience;\nTrades-people with business in the park;\nAny civilian activity a part of or incidental to the pursuit of a gainful occupation (e.g., guides);\nGovernment personnel (other than NPS employees) with business in the park;\nCitizens using NPS buildings for civic or local government business, or attending public hearings;\nOutside research activities (visits and overnights) if independent of NPS legislated interests (e.g. meteorological research).\n\n\nWhat this means is that the counts leave out a lot of people. This is worth thinking about when we evaluate what the numbers mean, and how the NPS achieves them (which we’ll discuss more below)\n\n\n\nSo now we know what is being collected. But let’s try to understand how it’s being collected. We can do this, in part, by exploring and visualising the data.\nFor example: let’s visualise the visits to Crater Lakes National Park, from 1979 to the present:\n\n\nCode\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette &lt;- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Crater Lake National Park\ncrater_lake &lt;- np_data %&gt;% filter(ParkName == \"Crater Lake NP\")\n\n# Visualize it\nggplot(data = crater_lake) + \n  geom_line(aes(x = \n  Year, y = RecreationVisits), \n  color = cb_palette[1]) +\n  labs(title = \"Crater Lake National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nWe see a lot of things in this data - not least of which is a tremendous rise in visitors in the 2010s - but one interesting observation is the sudden drop in visits in 2012. This isn’t caused by fewer people visiting: instead, it has more to do with how visitor numbers are counted.\nWhen it comes to counting visitors, the NPS uses a variety of techniques. At some parks, such as Alcatraz, it is simple: the park is only accessible via (ticketed) boat, and so NPS staff simply count the number of tickets. But other parks may have multiple entrances, and feature visitors arriving via car, bus, or on foot. It quickly becomes impractical to have staff at every entrance, 24 hours a day, just in case someone arrives.\nInstead, the NPS uses a variety of techniques - some automated, some manual. These include:\n\nInduction loop counters - magnetised coils of wire under the road that “trip” when a vehicle passes over them;\nTraffic counters, which manually increment a counter when a vehicle passes through a gate;\nExtracting data from ticketing machines.\n\n\n\n\nAn example of an induction loop installed under a road\n\n\nAlongside all of that, NPS rangers do, on many occasions, manually count people who arrive - particularly when one of the usual mechanisms doesn’t count. And that’s exactly what happened here; according to the NPS data logs, the induction loop counter at one of the main entrances simply broke in January, and wasn’t repaired for (at a minimum) several months. You can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears visits entirely tail off in 2020, as a result of the traffic counter being broken for years:\n\n\nCode\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data &lt;- np_data %&gt;% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\n\n\n\nNow that we’ve talked about how data is collected (and the fragility of some of those methods), it’s a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see Exercise 1.\n\n\n\nChanges in data don’t only stem from changes in data collection, but also the underlying reality of what is being measured. Let’s take a look at the visitor data from Kobuk Valley National Park:\n\n\nCode\n# Filter down to Kobuk Valley National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[3]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nMost people’s eyes will immediately be drawn to the drastic drop in 2014-15, and for good reason! But the cause is familiar: it’s about data collection. As the park report notes, ” The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.“.\nBut another question would be: why the drop-off in 2018-19? It’s too early for the cause to be COVID. Instead, the cause is administrative; government shut-downs in that era led to a reduction of funding, and correspondingly the closure of various attractions at the park. The result: a lack of funding leads to a reduced visitor count - a visitor count that is often used, remember, to argue for funding. This highlights one of the ways in which seemingly-descriptive data used to make decisions can represent the state of those decisions, more than some natural “baseline”.\nAnother kind of issue of “representing reality” can be found if we look at the visitor data for Mount Rainier:\n\n\nCode\n# Filter down to Mount Rainier National Park\nrainier_data &lt;- np_data %&gt;% filter(ParkName == \"Mount Rainier NP\")\n\n# Visualise it\nggplot(data = rainier_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[4]) +\n  labs(title = \"Mount Rainier National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nOnce again, we see both a COVID-19 dropoff - but also a continued dropoff beyond that. Looking at the visitation comments explains why; flooding, fires and a blizzard drastically impeded the ability of people to get to the park, and the possibility of areas of the park opening at all.\n\n\n\nAs all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of any data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\nSometimes this leads to odd-looking decisions. For example: at Assateague Island National Seashore, there are two entrances (one in Maryland, and one in Virginia). At both entrances, they use a traffic counter to count vehicles. At both entrances, they get from vehicles to visitors by multiplying the number of vehicles by an estimate of how many people each vehicle contains. But at the Maryland entrance, that’s 2.9. At the Virginia entrance, it’s 3.2.\n\n\n\nReader note: this exercise will direct students, on a group (or individual) basis, to the NPS index of how different parks calculate different multipliers and metrics, and ask them to log or note unusual or unexplained differences in how this is done.\n\n\n\nAs well as multiplying up, there’s also counting down: some parks register “zero” as the number of visitors they attracted in a year:\n\n\n\n\n\nCode\n# Filter down to just zeros\nzero_data &lt;- np_data %&gt;% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\n\n\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has “zero counts”, Kobuk Valley National park, we see it’s hardly overrun with people even when the count isn’t zero:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nIf we look at the visitation comments again, what we see is that “The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” Which is entirely reasonable, in isolation: but we’ve also seen a lot of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?\n\n\n\nReader note: in this exercise, users will try to use public data - twitter posts, flickr photos, etc, etc - to try and find situations where people are identifying themselves as being at a park that, officially, has 0 people present at that time Have them go through public data and try to find proof the counts of 0 are “wrong”\n\n\n\n\n\nCode\nviewof search = Inputs.search(data, {\n  placeholder: \"Search\"\n})\n\n\n\n\n\n\n\n\n\nCode\ndata = d3.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2022-National-Park-Visits-By-State.csv\", d3.autoType)\n\n\n\n\n\n\n\n\n\nCode\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\n\n\n\nCode\ncolor = d3\n  .scaleLinear()\n  .domain([5000000, 1000000, 100000])\n  .range([\"#cafcc2\", \"#fce7c2\", \"#eb9494\"])\n\n\n\n\n\n\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\n\n\n\nRPython\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\nFeb 26, 2024\n\n\nIntroduction to DPLYR with National Park Visitation Data (Solution)\n\n\ndplyr, solution\n\n\n\n\nFeb 26, 2024\n\n\nggplot Customization with National Park Visitation Data (Solution)\n\n\nggplot, advanced, solution\n\n\n\n\nFeb 26, 2024\n\n\nIntroduction to DPLYR with National Park Visitation Data (Exercise)\n\n\ndplyr, exercise, solution\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\nDevices breaking is inevitable - but as the different scales of the Carlsbad and Crater Lake outages indicate, they get fixed at different rates, in different locations. There are a lot of reasons for this, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it—and the less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritised by the repair teams that can be dispatched.\nThinking about this, look at the locations of the following parks. Suppose that each one has an outage in their induction loop: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n\n\nPark\nPriority (1-5)\nReason\n\n\n\n\nAcadia NP\n\n\n\n\nLassen Volcanic NP\n\n\n\n\nSaguaro NP\n\n\n\n\nYosemite NP\n\n\n\n\nMammoth Cave NP"
  },
  {
    "objectID": "posts/np-data/np-data.html#introduction",
    "href": "posts/np-data/np-data.html#introduction",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "This dataset contains the number of visits, per year, to each of the 63 National Parks administered by the United States National Park Service (NPS), from 1979 to the present. The NPS also collects visitation data for other park units, such as national battlfieds, national rivers, and national monuments. However, information about other park units is not included in this particular dataset.\n\n\n\nCode\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x =&gt; d3.format('.2s')(x),*/\n    Year: x =&gt; d3.timeFormat(x),\n    RecreationVisits: x =&gt; html`&lt;div style='background:${color(x)}'&gt;${d3.format('.2s')(x)}&lt;/div&gt;`\n  }\n})\n\n\n\n\n\n\n\nThis particular dataset is drawn from data published by the NPS. Most (but not all) of the contextual information included here draws from material published by the NPS, as well. However, the original data is made available in an NPS data portal that is relatively hard to find, and its documentation is scattered across many different web pages, which is why we believe it is valuable to curate and publish it in a single place here.\nThis dataset was curated and published by Melanie Walsh, and the data essay was written by Os Keyes and Melanie Walsh."
  },
  {
    "objectID": "posts/np-data/np-data.html#history",
    "href": "posts/np-data/np-data.html#history",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "The National Park Service actually began recording information about park visits in 1904 (more than 100 years ago!). However, at this time, their visit collection methods were mostly informal, inconsistent, and low-tech. But over the next century, the NPS worked hard to make their data collection methods more reliable, consistent, and (in some but not all cases) high-tech.\nA big catalyst for the NPS getting serious about data collection was a new law. In 1965, the U.S. Congress passed a federal law that was very important for the NPS and for anybody who loves the outdoors: The Land and Water Conservation Fund Act of 1965. This act created a new source of government money specifically dedicated to protecting natural resources (i.e. to buying up land and water so that condo developers couldn’t do it first) and building up outdoor recreation infrastructure in the U.S.\nOne of the clauses in this act stipulated that the amount of money allocated to each recreation area should be “proportional to visitor use.” Because the NPS can’t function without money, they buckled down on counting visitor use. According to the NPS, over the next twenty years, they “developed and institutionalized a formal system for collecting, compiling and reporting visitor use data.”\nWhile today’s visit data collection system is far more formal and sophisticated than the one that the NPS used in 1904, there are still many inconsistencies, flaws, and limitations in this system. These shortcomings are largely unavoidable. Trying to record every single visit to a National Park — across dozens of different parks and geographic regions, many decades of time, countless different weather conditions and funding situations, and hundreds of millions of people — is pretty much impossible. In fact, one of the reasons that this dataset is so useful and illuminating is because it does a good job of communicating an important point: data can never reflect reality precisely.\nHowever, the NPS visitation data also does a good job of communicating why we might be interested in collecting and analyzing even flawed and approximate data, as we will dig into below."
  },
  {
    "objectID": "posts/np-data/np-data.html#where-did-the-data-come-from-who-collected-it",
    "href": "posts/np-data/np-data.html#where-did-the-data-come-from-who-collected-it",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "This National Park visitation data was originally organized and published by the NPS Social Science Program, a specific program tasked with coordinating visitor statistics across the parks. Thousands of staff members were also involved in the data collection process for individual parks, as we will elaborate below.\nThe original data was made available through the NPS Visitor Use Statistics data portal. Through this portal, you can generate reports and download data for many different park visitation categories and time periods— at both the national and individual park levels.\nTo download the data included here, we selected the “Query Builder for Public Use Statistics (1979 - Last Calendar Year)” report type. We then selected only National Parks; all possible years (1979-2022); all possible regions; only “Recreation Visits”; the additional fields of “State” and “Region”; as well as the option of an annual summary of visit counts (as opposed to monthly visit counts). We then downloaded this report as a CSV and published it to GitHub for easier access."
  },
  {
    "objectID": "posts/np-data/np-data.html#why-was-the-data-collected-how-is-the-data-used",
    "href": "posts/np-data/np-data.html#why-was-the-data-collected-how-is-the-data-used",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "As we’ve already discussed, one of the reasons that the NPS collects visit data is because the government basically requires it. But there are a lot of other reasons that the NPS collects this information.\nAs the NPS writes on their website, they use visit data to determine which facilities might need more or less attention, which parks might need more or less staff members and programs, and which hiking trails or bathrooms might need more or less maintenance. This information also helps the communities and businesses surrounding the parks understand how they can best share and support resources in a given area — services like emergency vehicles, sanitation, and water. If there are millions more people going on hikes in a particular area, and thus, inevitably, many more people requiring ambulance trips or rescue helicopters, that would be a very important thing for a community to know. It would be dangerous if visitors to National Parks suddenly and unexpectedly called all the emergency vehicles in town.\nThis visitation data also helps the NPS estimate the beneficial impact, economic and otherwise, that the parks have on nearby communities and the nation at large. These estimations are important because they help the parks advocate for more funding, support, attention, and collaboration.\n\nThe data can also be used for a variety of other purposes…. (such as?)"
  },
  {
    "objectID": "posts/np-data/np-data.html#whats-in-the-data-what-counts-as-a-visit",
    "href": "posts/np-data/np-data.html#whats-in-the-data-what-counts-as-a-visit",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "If we open the dataset and look at the first few rows, we will find five columns – “ParkName”, “Region”, “State”, “Year”, and “RecreationVisits”:\n\n\nCode\n# https://statsandr.com/blog/an-efficient-way-to-install-and-load-r-packages/\n\n# Load the dplyr package\nlibrary(dplyr, warn = FALSE)\n\n# Load National Park Visitation data\nnp_data &lt;- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\", stringsAsFactors = FALSE)\n\n## Look at the structure of the dataset\nnp_data %&gt;% slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nSequoia NP\nPacific West\nCA\n1996\n838060\n\n\nSaguaro NP\nIntermountain\nAZ\n1996\n671643\n\n\nHot Springs NP\nMidwest\nAR\n2003\n1561311\n\n\nPinnacles NP\nPacific West\nCA\n1999\n164854\n\n\nIsle Royale NP\nMidwest\nMI\n2016\n24966\n\n\nGreat Sand Dunes NP & PRES\nIntermountain\nCO\n2016\n388308\n\n\nYellowstone NP\nIntermountain\nWY\n1986\n2363756\n\n\nCongaree NP\nSoutheast\nSC\n1989\n25445\n\n\nGuadalupe Mountains NP\nIntermountain\nTX\n2005\n170383\n\n\nArches NP\nIntermountain\nUT\n1997\n858525\n\n\n\n\n\n\nThe first four are self-explanatory: but why is the fifth labelled “RecreationVisits” rather than “Visits”, or “Visitors”?\nThe answer is that what this dataset is tracking is more complicated and nuanced than “people who go to NPS properties”. People go to the national parks for a lot of reasons. While many are there for recreation, some travel through the parks, either because a highway runs through or because they live on “inholdings” (private property that is surrounded by a national park on all sides). Because of this, the NPS defines “Recreation Visits” as visits made by people who are not:\n\nusing park territory, roads, and facilities for their own convenience or as a part of their occupation. &gt; Reportable non-recreation visits include:\n\nPersons going to and from inholdings across significant parts of park land;\nCommuter and other traffic using NPS-administered roads or waterways through a park for their convenience;\nTrades-people with business in the park;\nAny civilian activity a part of or incidental to the pursuit of a gainful occupation (e.g., guides);\nGovernment personnel (other than NPS employees) with business in the park;\nCitizens using NPS buildings for civic or local government business, or attending public hearings;\nOutside research activities (visits and overnights) if independent of NPS legislated interests (e.g. meteorological research).\n\n\nWhat this means is that the counts leave out a lot of people. This is worth thinking about when we evaluate what the numbers mean, and how the NPS achieves them (which we’ll discuss more below)"
  },
  {
    "objectID": "posts/np-data/np-data.html#data-and-data-collection",
    "href": "posts/np-data/np-data.html#data-and-data-collection",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "So now we know what is being collected. But let’s try to understand how it’s being collected. We can do this, in part, by exploring and visualising the data.\nFor example: let’s visualise the visits to Crater Lakes National Park, from 1979 to the present:\n\n\nCode\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette &lt;- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Crater Lake National Park\ncrater_lake &lt;- np_data %&gt;% filter(ParkName == \"Crater Lake NP\")\n\n# Visualize it\nggplot(data = crater_lake) + \n  geom_line(aes(x = \n  Year, y = RecreationVisits), \n  color = cb_palette[1]) +\n  labs(title = \"Crater Lake National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nWe see a lot of things in this data - not least of which is a tremendous rise in visitors in the 2010s - but one interesting observation is the sudden drop in visits in 2012. This isn’t caused by fewer people visiting: instead, it has more to do with how visitor numbers are counted.\nWhen it comes to counting visitors, the NPS uses a variety of techniques. At some parks, such as Alcatraz, it is simple: the park is only accessible via (ticketed) boat, and so NPS staff simply count the number of tickets. But other parks may have multiple entrances, and feature visitors arriving via car, bus, or on foot. It quickly becomes impractical to have staff at every entrance, 24 hours a day, just in case someone arrives.\nInstead, the NPS uses a variety of techniques - some automated, some manual. These include:\n\nInduction loop counters - magnetised coils of wire under the road that “trip” when a vehicle passes over them;\nTraffic counters, which manually increment a counter when a vehicle passes through a gate;\nExtracting data from ticketing machines.\n\n\n\n\nAn example of an induction loop installed under a road\n\n\nAlongside all of that, NPS rangers do, on many occasions, manually count people who arrive - particularly when one of the usual mechanisms doesn’t count. And that’s exactly what happened here; according to the NPS data logs, the induction loop counter at one of the main entrances simply broke in January, and wasn’t repaired for (at a minimum) several months. You can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears visits entirely tail off in 2020, as a result of the traffic counter being broken for years:\n\n\nCode\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data &lt;- np_data %&gt;% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")"
  },
  {
    "objectID": "posts/np-data/np-data.html#exercise-thinking-about-where-and-how-and-why-mechanisms-are-likely-to-break",
    "href": "posts/np-data/np-data.html#exercise-thinking-about-where-and-how-and-why-mechanisms-are-likely-to-break",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Now that we’ve talked about how data is collected (and the fragility of some of those methods), it’s a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see Exercise 1."
  },
  {
    "objectID": "posts/np-data/np-data.html#data-and-reality",
    "href": "posts/np-data/np-data.html#data-and-reality",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Changes in data don’t only stem from changes in data collection, but also the underlying reality of what is being measured. Let’s take a look at the visitor data from Kobuk Valley National Park:\n\n\nCode\n# Filter down to Kobuk Valley National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[3]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nMost people’s eyes will immediately be drawn to the drastic drop in 2014-15, and for good reason! But the cause is familiar: it’s about data collection. As the park report notes, ” The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.“.\nBut another question would be: why the drop-off in 2018-19? It’s too early for the cause to be COVID. Instead, the cause is administrative; government shut-downs in that era led to a reduction of funding, and correspondingly the closure of various attractions at the park. The result: a lack of funding leads to a reduced visitor count - a visitor count that is often used, remember, to argue for funding. This highlights one of the ways in which seemingly-descriptive data used to make decisions can represent the state of those decisions, more than some natural “baseline”.\nAnother kind of issue of “representing reality” can be found if we look at the visitor data for Mount Rainier:\n\n\nCode\n# Filter down to Mount Rainier National Park\nrainier_data &lt;- np_data %&gt;% filter(ParkName == \"Mount Rainier NP\")\n\n# Visualise it\nggplot(data = rainier_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[4]) +\n  labs(title = \"Mount Rainier National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nOnce again, we see both a COVID-19 dropoff - but also a continued dropoff beyond that. Looking at the visitation comments explains why; flooding, fires and a blizzard drastically impeded the ability of people to get to the park, and the possibility of areas of the park opening at all."
  },
  {
    "objectID": "posts/np-data/np-data.html#compensating-for-data",
    "href": "posts/np-data/np-data.html#compensating-for-data",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "As all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of any data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\nSometimes this leads to odd-looking decisions. For example: at Assateague Island National Seashore, there are two entrances (one in Maryland, and one in Virginia). At both entrances, they use a traffic counter to count vehicles. At both entrances, they get from vehicles to visitors by multiplying the number of vehicles by an estimate of how many people each vehicle contains. But at the Maryland entrance, that’s 2.9. At the Virginia entrance, it’s 3.2."
  },
  {
    "objectID": "posts/np-data/np-data.html#exercise-compensating-for-data-outages",
    "href": "posts/np-data/np-data.html#exercise-compensating-for-data-outages",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Reader note: this exercise will direct students, on a group (or individual) basis, to the NPS index of how different parks calculate different multipliers and metrics, and ask them to log or note unusual or unexplained differences in how this is done."
  },
  {
    "objectID": "posts/np-data/np-data.html#data-decisions",
    "href": "posts/np-data/np-data.html#data-decisions",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "As well as multiplying up, there’s also counting down: some parks register “zero” as the number of visitors they attracted in a year:"
  },
  {
    "objectID": "posts/np-data/np-data.html#look-at-the-structure-of-the-dataset",
    "href": "posts/np-data/np-data.html#look-at-the-structure-of-the-dataset",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Code\n# Filter down to just zeros\nzero_data &lt;- np_data %&gt;% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nParkName\nRegion\nState\nYear\nRecreationVisits\n\n\n\n\nKobuk Valley NP\nAlaska\nAK\n2014\n0\n\n\nKobuk Valley NP\nAlaska\nAK\n2015\n0\n\n\nNational Park of American Samoa\nPacific West\nAS\n2003\n0\n\n\nKatmai NP & PRES\nAlaska\nAK\n1995\n0\n\n\n\n\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has “zero counts”, Kobuk Valley National park, we see it’s hardly overrun with people even when the count isn’t zero:\n\n\nCode\n# Filter down to Mount Rainier National Park\nkobuk_data &lt;- np_data %&gt;% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n\n\n\n\n\n\n\n\n\nIf we look at the visitation comments again, what we see is that “The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.” Which is entirely reasonable, in isolation: but we’ve also seen a lot of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?"
  },
  {
    "objectID": "posts/np-data/np-data.html#exercise-data-decisions",
    "href": "posts/np-data/np-data.html#exercise-data-decisions",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Reader note: in this exercise, users will try to use public data - twitter posts, flickr photos, etc, etc - to try and find situations where people are identifying themselves as being at a park that, officially, has 0 people present at that time Have them go through public data and try to find proof the counts of 0 are “wrong”"
  },
  {
    "objectID": "posts/np-data/np-data.html#exercise-1",
    "href": "posts/np-data/np-data.html#exercise-1",
    "title": "National Park Visitation Data",
    "section": "",
    "text": "Devices breaking is inevitable - but as the different scales of the Carlsbad and Crater Lake outages indicate, they get fixed at different rates, in different locations. There are a lot of reasons for this, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it—and the less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritised by the repair teams that can be dispatched.\nThinking about this, look at the locations of the following parks. Suppose that each one has an outage in their induction loop: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n\n\nPark\nPriority (1-5)\nReason\n\n\n\n\nAcadia NP\n\n\n\n\nLassen Volcanic NP\n\n\n\n\nSaguaro NP\n\n\n\n\nYosemite NP\n\n\n\n\nMammoth Cave NP"
  }
]