---
title: "Top 500 \"Greatest\" Novels (1021-2015)"
author: Anna Preus and Aashna Sheth
format: 
  html: default
  #ipynb: default
  pdf: default
  #docx: default
  #r: default
listing:
  id: exercise-posts
  contents: exercises
  exclude:
    categories: "dataset"
  sort: "date desc"
  type: table
  fields: [date, title, categories]
  categories: false
  sort-ui: false
  filter-ui: true
  image-height: 200px
date: "2024-04-10"
categories: [libraries, literature, readers, gender, metadata, full-text, public domain ]
image: "images/library-top-500-screenshot.png"
toc: true
toc-depth: 5
sidebar: 
  contents: auto
format-links: [pdf, docx]
code-fold: true
editor: visual
df-print: kable
jupyter: python3
code-tools: true
bibliography: references/references.bib
---

::: {.panel-tabset .nav-pills}
# Data Essay {#data-essay}

## Introduction

This dataset contains information on the top 500 novels most widely held in libraries, according to [OCLC](https://www.oclc.org/en/about.html?cmpid=md_ab), a global library organization with over 16,000 member libraries in over 100 countries. The dataset includes information on authors’ biographies, library holdings, and online engagement for each novel, as well as the full text for all works that are not currently under copyright (190 novels).

<br>

```{ojs .content-visible when-format="html" unless-format="pdf"}

//| echo: false

/*Inputs.table(search, data)*/

Inputs.table(search, {
  layout: "fixed",
  rows: 50,
  sort: "top_500_rank",
  reverse: false,
  format: {
    /*RecreationVisits: x => d3.format('.2s')(x),*/
    pub_year: x => d3.timeFormat(x),
    author_birth: x => d3.timeFormat(x),
    author_death: x => d3.timeFormat(x),
    gr_num_ratings_rank: x => html`<div style='background:${color(x)}'>${d3.format('.2s')(x)}</div>`
  }
})
```

<br>

```{ojs}
//| echo: false
formatted_library_data = library_data.map(d => {
  return Object.fromEntries(
    Object.entries(d).map(([key, value]) => [
      key,
      key === "pub_year" || key === "author_birth" || key === "author_death" ? new Date(value, 0, 1) : value
    ])
  );
});

```

```{ojs}
//| echo: false
import {SummaryTable} from "05930c2f8350fb92"
viewof summary_data = SummaryTable(formatted_library_data, {
  label: "Top 500 Novels Summary"
});
```


{{< downloadthis ../../../datasets/top-500-novels/library_top_500.csv dname = library_top_500 label = "Download Data" id=downloadbutton >}}


This dataset is based on a list of the [Top 500 Novels](https://www.oclc.org/en/worldcat/library100/top500.html) compiled by OCLC from information in their online database [WorldCat](https://search.worldcat.org/), the largest database of library records. The first section of the list was published online with great fanfare as the [Library Top 100](https://www.oclc.org/en/worldcat/library100.html) in 2019, accompanied by the claim that for novels, “literary greatness can be measured by how many libraries have a copy on their shelves.” 

We wondered about the implications of this claim and more broadly about what it means to base ideas of “literary greatness” on the number of libraries that hold a particular work. How do historical biases in systems of literary production, preservation, and circulation figure into these kinds of claims? And how do we even define what counts as a novel? 

To contextualize the initial list and dig into its claims about literary greatness, we collected information on each novel from a number of other databases, including [Wikipedia](https://www.wikipedia.org/), [Goodreads](https://www.goodreads.com/), [Project Gutenberg](https://www.gutenberg.org/), the [Virtual International Authority File (VIAF)](https://viaf.org/), and [Classify](https://www.oclc.org/go/en/classify-discontinuation.html) (a now-shuttered OCLC tool), which we have compiled here.

The dataset was created by Anna Preus and Aashna Sheth, who are also the authors of this data essay.     


## **HISTORY**

To start, what is a novel? Today, novels are so prevalent that the term is often applied to a much wider range of books than it actually describes. “Novel” is an umbrella term for works of longform fiction in a range of genres: romance, sci-fi, historical fiction, horror, detective fiction, westerns, etc. The term generally does not apply–although these distinctions can sometimes be fuzzy–to short fiction, poetry, plays, biographies, or other non-fiction forms. The word “novel” was first used to describe a “long fictional prose narrative” in the 1600s, and the form increased in popularity across the eighteenth and nineteenth centuries. Interestingly, OCLC’s list of top 500 novels extends much further back than this. The oldest work on the list is *The Tale of Genji*, a classic work of Japanese literature written over 1,000 years ago.

A key issue in literary studies is which books from the past we continue to read in the present, and which books from the present we will continue to read in the future. The vast majority of novels fall out of circulation shortly after they are published, quickly becoming part of what Margaret Cohen has called “the great unread.” When teachers assign texts in their classes and when literary scholars conduct research, they’re making choices about which texts continue to be valuable and important for people to read and study. 

The term “canon” in literary studies refers to texts that continue to be considered important over time. Ankhi Mukherjee defines the canon as “a set of texts whose value and readability have borne the test of time” noting that this “ involves not merely a work’s admission into an elite club, but its induction into ongoing critical dialogue and contestations of literary value.” Canonical works continue to be read, taught, and discussed, and in popular terminology they’re often considered “classics.” These are works you might read in a high school English class: F. Scott Fitzgerald’s *The Great Gatsby*, for example, or Harper Lee’s *To Kill a Mockingbird*. 

One of the things that defines a classic is the fact that it stays in print for a long period of time. When a book is published, it is issued in an edition with a specific number of physical copies. If the book is profitable, it may be re-issued in different editions over many years, and edited repeatedly by different scholars across time. If it becomes a classic, it is likely to be issued in dozens or hundreds of editions even long after the author’s death. 

In addition to classics, libraries are invested in making popular new novels available to readers. The Top 500 list includes many recently published best-sellers, including books in the *Harry Potter*, *Twilight*, and *Hunger Games* series. Some highly popular books go on to become classics–Charles Dickens’s *Great Expectations*, which was wildly successful in its day, is a good example. Many popular texts, though, do not become canonical. 

By focusing on the books that librarians around the world have chosen to continue to make available to readers, OCLC was able to create a list of widely read novels that includes both classic works and more recent, popular works that may not have received the same levels of literary acclaim. We wondered, though, how did OCLC’s data compare to other potential indicators of popularity or canonicity? And, for that matter, how was the list actually constructed?

## **WHERE DID THE DATA COME FROM? WHO COLLECTED IT?**

The initial list of Top 500 novels was collected by a team at OCLC, the non-profit organization that manages WorldCat. It was compiled based on analysis of data in WorldCat, which consists of catalog records created by librarians around the world, and entered into WorldCat.

Building on this list, we compiled data from a number of other databases, including Project Gutenberg, VIAF, and Wikipedia–a process that is described in greater detail below. 


##  **WHY WAS THE DATA COLLECTED? HOW IS THE DATA USED?**

OCLC’s goal in producing the Top 500 list seems to be to encourage library patronage and reading. The website for the list includes a “Librarians Kit” with a variety of publicity materials–from printable bookmarks to Instagram tiles-that can help bring attention to books in the Top 500 list within libraries’ collections. 


![](images/top_500_kit.png "image_tooltip")


Our goal was to collect additional data to understand better how the list was constructed, and to contextualize and nuance its claims about literary greatness.


## **WHAT’S IN THE DATA? WHAT MAKES A BOOK A “TOP NOVEL”?**

The Top 500 list represents a massive data extraction and analysis effort on the part of OCLC. While they do not provide detailed information on how the list was compiled, they do offer a brief explanation of the process that went into creating the list on their [FAQ page](https://www.oclc.org/en/worldcat/library100/faq.html) (written in the context of the top 100, but also applies to the top 500):


   > Materials in libraries are described and tracked in WorldCat in two ways. Any specific work of literature, music, art, history, etc., has an associated **catalog record**. This describes the item in a general sense. Every copy of the same book, for example, shares the same record. WorldCat also tracks library **holdings**, which indicate that a specific library has (or holds) at least one copy of that item.


  > The Library 100 is based on the total number of holdings for a specific novel across all libraries that have registered that information in WorldCat. When a library tells OCLC, “We have a copy of that book available,” that counts as a holding, and in the case of The Library 100, counts as +1 toward its ranking on the list.

This process initially sounds straightforward: to create the Top 500 list, the OCLC team presumably searched the title of a work, counted the number of libraries that held each title, and published the first 500. But it turns out it’s actually much more complicated than that. In WorldCat, records are stored by edition, meaning that each edition of a particular title has its own catalog record. An individual title like, say, Miguel de Cervantes’s *Don Quixote*, may have been released in hundreds or thousands of editions since its initial publication. 

This means that when developing the list, the OCLC team actually had to find all the editions of a specific title and sum the number of libraries that hold that edition across all editions. **Thus the top 500 list is not only a representation of how many libraries carry the work, but a representation of how many times a book has been re-edited and re-issued; the more editions a book has, the more records are created and the more copies of a book a library may hold.** Often, there are duplicate records for individual editions, which may affect the overall count of copies tallied by the OCLC. And when a work is translated into different languages, all the editions of all the translations are also recorded in WorldCat, which also figures into the count of total holdings for each novel. 


##  **HOW WAS THE DATA COLLECTED? WHAT ADDITIONAL DATA WAS ADDED?**

We wanted to contextualize the Library Top 500 list by compiling additional information on each novel from a range of other sources. We focused on gathering three main categories of information: information that could help us understand what types of works–and whose works–were included on the list, data that could potentially provide alternate measures of popularity or canonicity, and the full text of each novel that was in the public domain. We collected information from the following sources:

**WorldCat**: we used the now-shuttered OCLC tool Classify to gather data from WorldCat on the top 100 most widely held editions of each of the 500 novels on the list. We recorded total library holdings for these top 100 editions. We consider number of editions as a potential alternate measure of canonicity, although it is necessarily affected by the amount of time that has passed since the initial publication of the novel.  

**VIAF: **The Virtual International Authority File is an OCLC-run database that contains structured records–called “name authority files”–for individual authors and creators. We used VIAF to gather information on authors whose novels were included on the list, including their birth and death dates, nationalities, genders, and occupations.

![Examplf of author VIAF](images/viaf_example.png "image_tooltip")

**Wikipedia: **we used Wikipedia, the popular, free, volunteer-authored encyclopedia, to identify the year of first publication for each novel on the list.

**Goodreads: **Goodreads, which is owned by Amazon, is the largest social networking site related to books, with over 150 million members. Itt allows users to rate, review, and discuss a huge range of texts. We drew on data from Goodreads as a potential alternate indicator of texts’ popularity, collecting total number of reviews, total number of ratings, and average overall rating for each novel on the list. 

**Project Gutenberg**: We used Project Gutenberg to access the full-text of all novels on the list that are currently in the public domain, or in other words, out of copyright. We chose Project Gutenberg because their eBooks are edited by volunteers, whereas many larger content repositories, like Internet Archive and HathiTrust, only make available machine-generated transcriptions of historical texts, which tend to be less accurate. 

Our work creating this dataset not only builds on the work of the OCLC team who compiled the Top 500 list, but on the labor of the thousands of librarians who created records held in WorldCat and VIAF, of the volunteers who transcribed texts for Project Gutenberg and wrote articles for Wikipedia, and of the social media users who reviewed and rated books on Goodreads. 


## **ACKNOWLEDGING BIAS**

The Top 500 List provides an unprecedented opportunity to consider what works libraries around the world have on their shelves. This, in turn, serves as an important indicator of books’ continued relevance to readers. As OCLC points out, “libraries offer access to trendy and popular books. But, they don’t keep them on the shelf if they’re not repeatedly requested by their communities over the years.” 

At the same time, there are biases in what gets kept on library shelves, and in which library shelves are being considered. The libraries that OCLC works with are disproportionately located in Europe and North America and OCLC uses cataloging systems developed in English-language contexts. The list is distinctly skewed toward works by White, European and American men, as is much of the history of English literary production, but it is also difficult to tease apart this historical bias from potential compounding biases in the underlying data, in the data collection process, or in library cataloging systems more broadly.

OCLC acknowledges broad biases in the list in a section titled, “Why isn’t the list more diverse?” writing, “The list emphasizes many books that we tend to think of as ‘classics,’ because those are the novels most often translated, retold in different editions, taught and widely distributed in library collections. Because of this, the list tends to reflect more dominant cultural views.” Although OCLC acknowledges this general bias towards works considered classics, more specific forms of bias aren’t made apparent in the list itself, which only includes the title and author for each novel. 


![](images/top_ten_complete_500.png "image_tooltip")

Each of these works and authors, of course, deserves careful consideration in their own right, but by compiling additional information into dataset, we can begin to see some of these biases as well as trends across the list more clearly.

## **WHAT’S IN THE DATA? WHAT MAKES A BOOK A “TOP NOVEL”?**

By building on OCLC’s initial list and adding a range of information from other databases, we wanted to create a dataset that would offer opportunities to connect metadata analysis and full-text analysis in relation to a historically significant corpus of texts. To this end, we’ve included a brief exploration of the data below, as well as suggested activities, and some ideas for future areas of inquiry.

We split up our analysis into three portions: metadata analysis, rank analysis, and full-text analysis. You can follow our analysis in the notebook [here](https://drive.google.com/file/d/1gnina8FoyERuin3sDW57GoKh2d6ew1Mt/view?usp=sharing). We first ask questions about the authors represented in the current top 500 list. Then, we compare rankings based on editions, holdings, and GoodReads popularity with the top 500 list. In [another notebook](https://drive.google.com/file/d/1FgPq4nDUmqsaWBkYMEfDEb1OPFuqOYGi/view?usp=sharing), we analyze the full text of works split up by genre.

## **METADATA ANALYSIS**

Let's start by reading our data into a pandas dataframe. A pandas dataframe is a structure used to hold file data. This structure has efficient methods used for manipulating and visualizing data.

```{python}
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/melaniewalsh/responsible-datasets-in-context/main/datasets/top-500-novels/library_top_500.csv", sep=',', header=0, low_memory=False)
```
Now, we can answer various questions using this structure, which we've named `df`.

For example, let's look at counts related to author gender and name.

```{python}
df["author_gender"].value_counts()
```
We see that about 70% of authors on the list are male and 30% are female.

```{python}
df["author"].value_counts().head(10)
```
Above are the top 10 authors and the number of times they appear. John Grisham appears a stunning 19 times!

Next, we can delve into some visualization work to understand where authors are from and what timeframe of publication is most represented in the top 500 list.

```{python}
import numpy as np

bins = np.arange(1000, 2060, 50)
bars = df['pub_year'].plot.hist(bins=bins, edgecolor='w')
plt.xticks(rotation='vertical');
plt.xticks(bins);
```
We can see that most books on the list were published between 1950 and 2000. Let's take a look at information about the oldest and newest books on the list.

```{python}
from IPython.display import display

print("Oldest Book(s):")
display(df[df["pub_year"]==df["pub_year"].min()])
print("Newest Book(s):")
display(df[df["pub_year"]==df["pub_year"].max()])
```
Let's take a look at where the authors are from!

```{python}
df["author_nationality"].value_counts().head(5)
```
Finally, let's unpack the differences between the GoodReads ratings and the top 500 ratings. First, we should think about how we want to compare the two lists. Given that we have listed rankings by average rating and number of ratings, which metric would be better to use? Would we want to create another metric?

For our purposes, we decided to use number of ratings, instead of average rating, as OCLC measures popularity by number of holdings, not how much patrons say they enjoy reading the books.

```{python}
def top_5_comparison(col_name):
  print(df[["title", "author", "top_500_rank", col_name]].head(5))

  sorted = df.sort_values(by=[col_name])
  print(sorted[["title", "author", "top_500_rank", col_name]].head(5))

top_5_comparison("gr_num_ratings_rank")
```

Above you can see that the GoodReads rankings and the top 500 rankings aren't very aligned! What factors affect popularity on GoodReads compared to OCLC?

```{python}
import math

def print_rankings(d, col_name):
    rank_B = d[col_name]
    rank_A = d["top_500_rank"]
    title = d["title"]
    points_moved = 0
    if (math.isnan(rank_B)):
      points_moved = 501
    else:
      if rank_B > int(rank_A):
          points_moved = rank_B - rank_A
          print(f"\u001b[31m ▼ -{int(points_moved)} {title}")
      elif rank_B < rank_A:
          points_moved = rank_A - rank_B
          print(f"\u001b[32m ▲ +{int(points_moved)} {title}")
      else:
          print(f"\u001b[30m ● {int(points_moved)} {title}")
    d["points_moved"] = int(points_moved)
    return d

df = df.apply(lambda d: print_rankings(d, "gr_num_ratings_rank"), axis=1)
```

Let's see which novels had the most movement up or down!

```{python}
sorted = df.sort_values(by=['points_moved'])
print(sorted[["title", "author", "points_moved", "top_500_rank", "gr_num_ratings_rank"]].head(10).to_string(index=False))

sorted = df.sort_values(by=['points_moved'], ascending=False)
print(sorted[["title", "author", "points_moved", "top_500_rank", "gr_num_ratings_rank"]].head(10).to_string(index=False))
```

Above we see that Steinbeck's *The Winter of Our Discontent*, stayed at the same ranking of 397. *Pride and Prejudice* remained quite high as well.

*20,000 Leagues Under the Sea* dropped the most, from rank 37 in the top 500 list, to rank 481 in the goodreads list! *Harry Potter and The Half-Blood Prince* and *The Sea of Monsters* rose the most.

df['points_moved'].mean()

```{python}
df['points_moved'].mean()
```

Let's take a look at some of these metrics for rankings based on number of editions and total holdings.

```{python}
df = df.apply(lambda d: print_rankings(d, "oclc_editions_rank"), axis=1)

df = df[df["points_moved"] <= 500]
top_5_comparison("oclc_editions_rank")

df['points_moved'].mean()
smaller_df = df.head(10)
smaller_df['points_moved'].mean()

df = df.apply(lambda d: print_rankings(d, "oclc_holdings_rank"), axis=1)

top_5_comparison("oclc_holdings_rank")

df['points_moved'].mean()
smaller_df = df.head(10)
smaller_df['points_moved'].mean()
```
Comparing the average points of movement between the top 500 and 3 other ranking lists, we can see that the novels moved the least when compared to the number of holdings ranking (45 pts). Novels were 2x more likely to move positions when compared to the number of editions ranking (82 pts) and 3x more likely to move when compared to GoodReads rankings (137 pts).

<TODO: how to show significant relationship between num holdings, top 500 and num holdings, num editions, but NOT goodreads?>

Within the top 10 rankings specifically, only 2 books were not the same when compared to number of holdings, 4 books were not the same when compared to editions rankings, and 9 books were not the same when compared to GoodReads rankings.

## **FULL-TEXT ANALYSIS**

Now we can look at the `final_merged_dataset.tsv` file, which also includes the full-text of all the novels on the list that are in the public domain. We will be working with the  `full_text` column, which is a cleaned version of each book.

```{python}
import pandas as pd
import requests
import re
from bs4 import BeautifulSoup
import random
```

Let's start by analyzing the type-token ratio of our texts by genre. The type-token ratio will tell us which genres contain the most unique words.

The type-token ratio is a simple expression that calculates # of unique words / total words in a selection. As you may be able to surmise, sometimes this ratio is naturally higher for shorter books. To avoid this bias, we randomly select a contiguous 1000 word sample from each book and average the scores across genres.

It's helpful to be able to store all of our data in a dataframe, but sometimes we want to work with just one column of the data and converting it into a different datatype can be helpful. Here we're converting all the information in the column "text" into a list.

```{python}
def get_ttr(text):
  if (pd.isnull(text)):
    return 1.1 # a ratio greater than 1 is impossible, so we won't count these when doing our averages
  else:
    text = text.lower()
    punctuations = "-,.?!;#: \n\t"
    no_punct = text.strip(punctuations)
    tokens = text.split()

    trial = 0
    avg_ttr = 0
    while (trial < 10):
      random_token_num = random.randrange(0, len(tokens)-1000)
      sample = tokens[random_token_num:(random_token_num+1000)]
      trial += 1
      avg_ttr += float(len(set(sample)))/1000

    return avg_ttr/10

    import csv

df = pd.read_csv("final_merged_dataset.tsv", sep='\t', header=0, low_memory=False)
df["ttr"] = df["full_text"].apply(get_ttr)

cleaned = df[df["ttr"] <= 1] # drop all rows where ttr is not applicable
grouped = cleaned.groupby('genre')
avg_ttr = grouped["ttr"].mean().sort_values(ascending=False)
print(avg_ttr)

sorted = cleaned.sort_values(by=['ttr'], ascending=False)
print(sorted[["title", "author", "ttr", "genre"]].head(10).to_string(index=False))
```


::: {.callout-tip}
## Activity 1

    &lt;**Activity** looking into the original languages of novels in the dataset?> For more, see [Activity 1](#exercise-1).
:::


## **CONCLUSION**



# Explore the Data {#tabset-1-2}


```{ojs}
//| echo: false
//| output: false
library_data = d3.csv("https://raw.githubusercontent.com/melaniewalsh/responsible-datasets-in-context/main/datasets/top-500-novels/library_top_500.csv", d3.autoType)

use_data = d3.csv("https://raw.githubusercontent.com/melaniewalsh/responsible-datasets-in-context/main/datasets/national-parks/US-National-Parks_Use_1979-2023_By-Month.csv", d3.autoType)
```

```{ojs}
//| echo: false
//| output: false


filtered = library_data.filter(function(penguin) {
  return bill_length_min < penguin.bill_length_mm &&
         islands.includes(penguin.island);
})
```

```{ojs}
//| echo: false
color = d3
  .scaleLinear()
  .domain([0, 100, 300])
  .range(["#cafcc2", "#fce7c2", "#eb9494"])
```
<br>

## Library Top 500

```{ojs}
//| echo: false
viewof search = Inputs.search(library_data, {
  placeholder: "Search"
})
```

<br>

```{ojs}
//| echo: false

/*Inputs.table(search, data)*/

Inputs.table(search, {
  layout: "fixed",
  rows: 50,
  sort: "top_500_rank",
  reverse: false,
  format: {
    /*RecreationVisits: x => d3.format('.2s')(x),*/
    pub_year: x => d3.timeFormat(x),
    author_birth: x => d3.timeFormat(x),
    author_death: x => d3.timeFormat(x),
    gr_num_ratings_rank: x => html`<div style='background:${color(x)}'>${d3.format('.2s')(x)}</div>`
  }
})
```

{{< downloadthis ../../../datasets/top-500-novels/library_top_500.csv dname = library_top_500 label = "Download Data" id = downloadbutton >}}


# Exercises {#exercises}

::: {.panel-tabset .nav-pills}
# R

::: {#exercise-posts}
:::

# Python
:::

# Discussion & Activities {#discussion-and-activities}

## Activity 1 {#exercise-1}

It is inevitable that the devices that the National Park Service uses to count visits to the parks — like induction loop counters installed on the road — will break. But they will also get *fixed* at different rates, in different locations, as we could see in the case of Crater Lake National Park (where a counter was fixed quickly) and Carlsbad Caverns National Park (where a broken counter from 2019 still has not been fixed).

There are many reasons for these disparities, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it. The less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritized by the repair teams that can be dispatched.

With this in mind, look at the locations of the following parks. Suppose that each one has an outage in their induction loop counter: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.

| Park               | Priority (1-5) | Reason |
|--------------------|----------------|--------|
| Acadia NP          |                |        |
| Lassen Volcanic NP |                |        |
| Saguaro NP         |                |        |
| Yosemite NP        |                |        |
| Mammoth Cave NP    |                |        |

## Activity 2 {#exercise-2}

The National Park Service sometimes fills in missing data with hard numbers or approximates data by applying special mathematical formulas. This is necessary work, but it is also under-explained work.

To see this in action, go to [the NPS page that documents park reports](https://irma.nps.gov/Stats/Reports/Park) and down the "Visitor Use Counting Procedures" PDF for three different parks.

How are the procedures for these three parks similar or different? What kind of effect do you think this has on the resulting data? What do you think is the best of documenting this information and communicating it to users of the data?

## Activity 3

In 2014 and 2015, Kobuk Valley National Park reported that there were zero visitors to the park.

Use publicly available internet data - Twitter posts, Flickr photos, etc - to try and find evidence of people visiting the park (there is existing evidence!). 

Based on your findings, how do you think, differently, if at all, about Kobuk Valley's decision to record zero visits and about alternative methods for counting visits?

:::

