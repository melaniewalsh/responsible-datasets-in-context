{
  "hash": "c989c52e9c0a12f2836eea7b72032d42",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"National Park Visitation Data\"\nlisting:\n  id: exercise-posts\n  contents: exercises\n  exclude:\n    categories: \"dataset\"\n  sort: \"date desc\"\n  type: table\n  fields: [date, title, categories]\n  categories: false\n  sort-ui: false\n  filter-ui: true\n  image-height: 200px\ndate: \"2024-02-26\"\ncategories: [line-plots, data-collection, uncertainty]\nimage: \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/Logo_of_the_United_States_National_Park_Service.svg/1200px-Logo_of_the_United_States_National_Park_Service.svg.png\"\ntoc-title: Table of Contents\ntoc: true\ntoc-expand: true\ntoc-depth: 5\ntoc-location: right\nformat: \n  html: default\n  ipynb: default\n  pdf: default\n  docx: default\n  #r: default\ncode-fold: true\neditor: visual\ndf-print: kable\nR.options:\n  warn: false\ncode-tools: true\nnavbar:\n    background: primary\n    search: true\n    left:\n      - Intro-to-DPLYR-NP.qmd\n---\n\n\n# National Park Visitation Data\n\n::: {.panel-tabset .nav-pills}\n# Data Essay {#data-essay}\n\n## Introduction\n\nThis dataset contains the number of visits, per year, to each of the 63 National Parks administered by the United States National Park Service (NPS), from 1979 to the present. The NPS also collects visitation data for other park units, such as [national battlfieds, national rivers, and national monuments]((https://www.nps.gov/aboutus/national-park-system.htm)). However, information about other park units is not included in this particular dataset.\n\n<br>\n\n\n```{ojs}\n//| echo: false\n\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 10,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x => d3.format('.2s')(x),*/\n    Year: x => d3.timeFormat(x),\n    RecreationVisits: x => html`<div style='background:${color(x)}'>${d3.format('.2s')(x)}</div>`\n  }\n})\n```\n\n\nThis particular dataset is drawn from data published by the NPS. Most (but not all) of the contextual information included here draws from material published by the NPS, as well. However, the original data is made available in an [NPS data portal](https://irma.nps.gov/Stats/) that is relatively hard to find, and its documentation is scattered across many different web pages, which is why we believe it is valuable to curate and publish it in a single place here.\n\nThis dataset was curated and published by Melanie Walsh, and the data essay was written by Os Keyes and Melanie Walsh.\n\n## History\n\nThe National Park Service actually began recording information about park visits in 1904 (more than 100 years ago!). However, at this time, their visit collection methods were mostly [informal, inconsistent, and low-tech](https://www.nps.gov/subjects/socialscience/statistics-history.htm). But over the next century, the NPS worked hard to make their data collection methods more reliable, consistent, and (in some but not all cases) high-tech.\n\nA big catalyst for the NPS getting serious about data collection was a new law. In 1965, the U.S. Congress passed a federal law that was very important for the NPS and for anybody who loves the outdoors: [The Land and Water Conservation Fund Act of 1965](https://www.everycrsreport.com/reports/RL33531.html). This act created a new source of government money specifically dedicated to protecting natural resources (i.e. to buying up land and water so that condo developers couldn't do it first) and building up outdoor recreation infrastructure in the U.S.\n\nOne of the clauses in this act stipulated that the amount of money allocated to each recreation area should be [\"proportional to visitor use.\"](https://www.nps.gov/subjects/socialscience/statistics-history.htm) Because the NPS can't function without money, they buckled down on counting visitor use. According to the NPS, over the next twenty years, they \"developed and institutionalized a formal system for collecting, compiling and reporting visitor use data.\"\n\nWhile today's visit data collection system is far more formal and sophisticated than the one that the NPS used in 1904, there are still many inconsistencies, flaws, and limitations in this system. These shortcomings are largely unavoidable. Trying to record every single visit to a National Park --- across dozens of different parks and geographic regions, many decades of time, countless different weather conditions and funding situations, and hundreds of millions of people --- is pretty much impossible. In fact, one of the reasons that this dataset is so useful and illuminating is because it does a good job of communicating an important point: data can *never* reflect reality precisely.\n\nHowever, the NPS visitation data also does a good job of communicating why we might be interested in collecting and analyzing even flawed and approximate data, as we will dig into below.\n\n## Where did the data come from? Who collected it? {#where-did-the-data-come-from-who-collected-it}\n\nThis National Park visitation data was originally organized and published by the [NPS Social Science Program](https://www.nps.gov/subjects/socialscience/visitor-use-statistics.htm), a specific program tasked with coordinating visitor statistics across the parks. Thousands of staff members were also involved in the data collection process for individual parks, as we will elaborate below.\n\nThe original data was made available through the [NPS Visitor Use Statistics data portal](https://irma.nps.gov/Stats/). Through this portal, you can generate reports and download data for [many different park visitation categories](https://irma.nps.gov/Stats/Reports/National) and time periods--- at both the national and individual park levels.\n\nTo download the data included here, we selected the [\"Query Builder for Public Use Statistics (1979 - Last Calendar Year)\"](https://irma.nps.gov/Stats/SSRSReports/National%20Reports/Query%20Builder%20for%20Public%20Use%20Statistics%20(1979%20-%20Last%20Calendar%20Year)) report type. We then selected only National Parks; all possible years (1979-2022); all possible regions; only \"Recreation Visits\"; the additional fields of \"State\" and \"Region\"; as well as the option of an annual summary of visit counts (as opposed to monthly visit counts). We then downloaded this report as a CSV and published it to GitHub for easier access.\n\n![](query-builder-csv-screenshot.png)\n\n## Why was the data collected? How is the data used?\n\nAs we've already discussed, one of the reasons that the NPS collects visit data is because the government basically requires it. But there are a lot of other reasons that the NPS collects this information.\n\nAs the NPS writes on their website, they use visit data to determine which facilities might need more or less attention, which parks might need more or less staff members and programs, and which hiking trails or bathrooms might need more or less maintenance. This information also helps the communities and businesses surrounding the parks understand how they can best share and support resources in a given area ---Â services like emergency vehicles, sanitation, and water. If there are millions more people going on hikes in a particular area, and thus, inevitably, many more people requiring ambulance trips or rescue helicopters, that would be a very important thing for a community to know. It would be dangerous if visitors to National Parks suddenly and unexpectedly called all the emergency vehicles in town.\n\nThis visitation data also helps the NPS estimate the beneficial impact, economic and otherwise, that the parks have on nearby communities and the nation at large. These estimations are important because they help the parks advocate for more funding, support, attention, and collaboration.\n\n![](NP-economic-benefit-poster.jpg){width=\"300px\"}\n\nThe data can also be used for a variety of other purposes.... (such as?)\n\n## What's in the data? What \"counts\" as a visit?\n\nIf we open the dataset and look at the first few rows, we will find five columns -- \"ParkName\", \"Region\", \"State\", \"Year\", and \"RecreationVisits\":\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://statsandr.com/blog/an-efficient-way-to-install-and-load-r-packages/\n\n# Load the dplyr package\nlibrary(dplyr, warn = FALSE)\n\n# Load National Park Visitation data\nnp_data <- read.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv\", stringsAsFactors = FALSE)\n\n## Look at the structure of the dataset\nnp_data %>% slice_sample(n = 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|ParkName                     |Region        |State | Year| RecreationVisits|\n|:----------------------------|:-------------|:-----|----:|----------------:|\n|Joshua Tree NP               |Pacific West  |CA    | 2004|          1243659|\n|Biscayne NP                  |Southeast     |FL    | 1995|           584519|\n|Katmai NP & PRES             |Alaska        |AK    | 1986|            41663|\n|Kenai Fjords NP              |Alaska        |AK    | 2019|           356601|\n|Voyageurs NP                 |Midwest       |MN    | 2001|           243374|\n|Wrangell-St. Elias NP & PRES |Alaska        |AK    | 1985|            23171|\n|Kobuk Valley NP              |Alaska        |AK    | 1982|             3775|\n|Katmai NP & PRES             |Alaska        |AK    | 2013|            28966|\n|Petrified Forest NP          |Intermountain |AZ    | 2007|           563590|\n|Acadia NP                    |Northeast     |ME    | 2018|          3537575|\n\n</div>\n:::\n:::\n\n\nThe first four are self-explanatory: but why is the fifth labelled \"RecreationVisits\" rather than \"Visits\", or \"Visitors\"?\n\nThe answer is that what this dataset is tracking is more complicated and nuanced than \"people who go to NPS properties\". People go to the national parks for a lot of reasons. While many are there for recreation, some travel *through* the parks, either because a highway runs through or because they live on \"inholdings\" (private property that is surrounded by a national park on all sides). Because of this, [the NPS defines](https://www.nps.gov/subjects/socialscience/nps-visitor-use-statistics-definitions.htm) \"Recreation Visits\" as visits made by people who are *not*:\n\n> using park territory, roads, and facilities for their own convenience or as a part of their occupation. \\> Reportable non-recreation visits include:\n>\n> -   Persons going to and from inholdings across significant parts of park land;\n> -   Commuter and other traffic using NPS-administered roads or waterways through a park for their convenience;\n> -   Trades-people with business in the park;\n> -   Any civilian activity a part of or incidental to the pursuit of a gainful occupation (e.g., guides);\n> -   Government personnel (other than NPS employees) with business in the park;\n> -   Citizens using NPS buildings for civic or local government business, or attending public hearings;\n> -   Outside research activities (visits and overnights) if independent of NPS legislated interests (e.g. meteorological research).\n\nWhat this means is that the counts leave out a lot of people. This is worth thinking about when we evaluate what the numbers mean, and how the NPS achieves them (which we'll discuss more below)\n\n## Data and data collection\n\nSo now we know what is being collected. But let's try to understand *how* it's being collected. We can do this, in part, by exploring and visualising the data.\n\nFor example: let's visualise the visits to Crater Lakes National Park, from 1979 to the present:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the \"ggplot2\" package (which we'll be using a lot more)\nlibrary(ggplot2)\n\n# Let's also load \"ggthemes\", which let's us use colorblind-compatible palettes. When we've only got one line, this will just be black.\nlibrary(ggthemes)\n\n# And specify the colorblind palette\ncb_palette <- colorblind_pal()(8)\n\n# Turn off scientific notation\noptions(scipen = 999)\n\n# Filter down to Crater Lake National Park\ncrater_lake <- np_data %>% filter(ParkName == \"Crater Lake NP\")\n\n# Visualize it\nggplot(data = crater_lake) + \n  geom_line(aes(x = \n  Year, y = RecreationVisits), \n  color = cb_palette[1]) +\n  labs(title = \"Crater Lake National Park Visits (1979 - Present)\")\n```\n\n::: {.cell-output-display}\n![](np-data_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nWe see a lot of things in this data - not least of which is a tremendous rise in visitors in the 2010s - but one interesting observation is the sudden drop in visits in 2012. This isn't caused by fewer people visiting: instead, it has more to do with how visitor numbers are counted.\n\nWhen it comes to counting visitors, the NPS uses a variety of techniques. At some parks, such as Alcatraz, it is simple: the park is only accessible via (ticketed) boat, and so NPS staff simply count the number of tickets. But other parks may have multiple entrances, and feature visitors arriving via car, bus, or on foot. It quickly becomes impractical to have staff at every entrance, 24 hours a day, just in case someone arrives.\n\nInstead, the NPS uses a variety of techniques - some automated, some manual. These include:\n\n-   Induction loop counters - magnetised coils of wire under the road that \"trip\" when a vehicle passes over them;\n-   Traffic counters, which manually increment a counter when a vehicle passes through a gate;\n-   Extracting data from ticketing machines.\n\nAlongside all of that, NPS rangers do, on many occasions, manually count people who arrive - particularly when one of the usual mechanisms doesn't count. And that's exactly what happened here; [according to the NPS data logs](https://irma.nps.gov/Stats/SSRSReports/Park%20Specific%20Reports/Monthly%20Visitation%20Comments%20By%20Park?Park=CRLA), the induction loop counter at one of the main entrances simply broke in January, and wasn't repaired for (at a minimum) several months. You can see a similar, but more severe, example at Carlsbad Caverns National Park, where it appears visits entirely tail off in 2020, as a result of [the traffic counter being broken](https://irma.nps.gov/Stats/SSRSReports/Park%20Specific%20Reports/Monthly%20Visitation%20Comments%20By%20Park?Park=CRLA) for *years*:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter down to Carlsbad Caverns National Park\ncarlsbad_data <- np_data %>% filter(ParkName == \"Carlsbad Caverns NP\")\n\n# Visualise it\nggplot(data = carlsbad_data) + \n  geom_line(aes(x = Year, y = RecreationVisits), color = cb_palette[2]) + \n  labs(title = \"Carlsbad Caverns National Park Visits (1979 - Present)\")\n```\n\n::: {.cell-output-display}\n![](np-data_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Exercise: thinking about where (and how, and why) mechanisms are likely to break\n\nNow that we've talked about how data is collected (and the fragility of some of those methods), it's a good time to think about how even the same method, deployed at different places, might be differently unreliable. For more, see [Exercise 1](#exercise-1).\n\n## Data and reality\n\nChanges in data don't only stem from changes in data collection, but also the underlying reality of what is being measured. Let's take a look at the visitor data from Kobuk Valley National Park:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter down to Kobuk Valley National Park\nkobuk_data <- np_data %>% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[3]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n```\n\n::: {.cell-output-display}\n![](np-data_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nMost people's eyes will immediately be drawn to the drastic drop in 2014-15, and for good reason! But the cause is familiar: it's about data collection. As the park report notes, \" [The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.](https://irma.nps.gov/Stats/SSRSReports/Park%20Specific%20Reports/Monthly%20Visitation%20Comments%20By%20Park?Park=MORA)\".\n\nBut another question would be: why the drop-off in 2018-19? It's too early for the cause to be COVID. Instead, the cause is administrative; government shut-downs in that era led to a reduction of funding, and correspondingly the closure of various attractions at the park. The result: a lack of funding leads to a reduced visitor count - a visitor count that is often used, remember, to *argue for funding*. This highlights one of the ways in which seemingly-descriptive data used to make decisions can represent the state of those decisions, more than some natural \"baseline\".\n\nAnother kind of issue of \"representing reality\" can be found if we look at the visitor data for Mount Rainier:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter down to Mount Rainier National Park\nrainier_data <- np_data %>% filter(ParkName == \"Mount Rainier NP\")\n\n# Visualise it\nggplot(data = rainier_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[4]) +\n  labs(title = \"Mount Rainier National Park Visits (1979 - Present)\")\n```\n\n::: {.cell-output-display}\n![](np-data_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nOnce again, we see both a COVID-19 dropoff - but also a continued dropoff beyond that. [Looking at the visitation comments](https://irma.nps.gov/Stats/SSRSReports/Park%20Specific%20Reports/Monthly%20Visitation%20Comments%20By%20Park?Park=MORA) explains why; flooding, fires and a blizzard drastically impeded the ability of people to get to the park, and the possibility of areas of the park opening at all.\n\n## Compensating for data\n\nAs all of this should suggest, NPS data is always somewhat approximate. Reductions in funding, damage to counting equipment, natural events, or simply the inevitably-fallible nature of *any* data collection means that data requires a certain amount of prediction, guesswork and massaging to look complete.\n\nSometimes this leads to odd-looking decisions. For example: at Assateague Island National Seashore, there are two entrances (one in Maryland, and one in Virginia). At both entrances, they use a traffic counter to count vehicles. At both entrances, they get from vehicles to visitors by multiplying the number of vehicles by an estimate of how many people each vehicle contains. But at the Maryland entrance, that's 2.9. At the Virginia entrance, it's 3.2.\n\n## Exercise: compensating for data outages\n\n*Reader note: this exercise will direct students, on a group (or individual) basis, to the NPS index of how different parks calculate different multipliers and metrics, and ask them to log or note unusual or unexplained differences in how this is done.*\n\n## Data decisions\n\nAs well as multiplying up, there's also counting down: some parks register \"zero\" as the number of visitors they attracted in a year:\n\n## Look at the structure of the dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter down to just zeros\nzero_data <- np_data %>% filter(RecreationVisits == 0)\n\n# Show some of them\nslice_sample(.data = zero_data, n = 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|ParkName                        |Region       |State | Year| RecreationVisits|\n|:-------------------------------|:------------|:-----|----:|----------------:|\n|Kobuk Valley NP                 |Alaska       |AK    | 2014|                0|\n|Kobuk Valley NP                 |Alaska       |AK    | 2015|                0|\n|National Park of American Samoa |Pacific West |AS    | 2003|                0|\n|Katmai NP & PRES                |Alaska       |AK    | 1995|                0|\n\n</div>\n:::\n:::\n\n\nLooking at the parks and regions, we can maybe infer why; they are all in extremely rural or underresourced areas, and probably see few visitors to begin with. If we look at the visitors over time for one park that has \"zero counts\", Kobuk Valley National park, we see it's hardly overrun with people even when the count *isn't* zero:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter down to Mount Rainier National Park\nkobuk_data <- np_data %>% filter(ParkName == \"Kobuk Valley NP\")\n\n# Visualise it\nggplot(data = kobuk_data) + \n  geom_line(aes(x = Year, y = RecreationVisits ), color = cb_palette[6]) +\n  labs(title = \"Kobuk Valley National Park Visits (1979 - Present)\")\n```\n\n::: {.cell-output-display}\n![](np-data_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nIf we look at the visitation comments again, [what we see](https://irma.nps.gov/Stats/SSRSReports/Park%20Specific%20Reports/Monthly%20Visitation%20Comments%20By%20Park) is that \"The park is developing a new counting system and has made the decision not to report visitor counts until the new system is in place.\" Which is entirely reasonable, in isolation: but we've also seen a *lot* of parks in more highly-frequented areas that have new systems developed and choose to (for example) average previous years, rather than simply declare that nobody visited. What are the politics of the choices in these scenarios?\n\n## Exercise: data decisions\n\n*Reader note: in this exercise, users will try to use public data - twitter posts, flickr photos, etc, etc - to try and find situations where people are identifying themselves as being at a park that, officially, has 0 people present at that time Have them go through public data and try to find proof the counts of 0 are \"wrong\"*\n\n# Explore the Data {#tabset-1-2}\n\n\n```{ojs}\n//| echo: false\nviewof search = Inputs.search(data, {\n  placeholder: \"Search\"\n})\n```\n\n```{ojs}\n//| echo: false\n//| output: false\ndata = d3.csv(\"https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2022-National-Park-Visits-By-State.csv\", d3.autoType)\n```\n\n```{ojs}\n//| echo: false\n//| output: false\n\n\nfiltered = data.filter(function(penguin) {\n  return bill_length_min < penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n```\n\n```{ojs}\n//| echo: false\ncolor = d3\n  .scaleLinear()\n  .domain([5000000, 1000000, 100000])\n  .range([\"#cafcc2\", \"#fce7c2\", \"#eb9494\"])\n```\n\n```{ojs}\n//| echo: false\n\n/*Inputs.table(search, data)*/\n\nInputs.table(search, {\n  layout: \"fixed\",\n  rows: 50,\n  sort: \"Year\",\n  reverse: true,\n  format: {\n    /*RecreationVisits: x => d3.format('.2s')(x),*/\n    Year: x => d3.timeFormat(x),\n    RecreationVisits: x => html`<div style='background:${color(x)}'>${d3.format('.2s')(x)}</div>`\n  }\n})\n```\n\n\n# Exercises {#exercises}\n\n::: {.panel-tabset .nav-pills}\n# R\n\n::: {#exercise-posts}\n:::\n\n# Python\n:::\n\n# Discussion & Activities {#discussion-and-activities}\n\n## Activity 1 {#exercise-1}\n\nDevices breaking is inevitable - but as the different scales of the Carlsbad and Crater Lake outages indicate, they get *fixed* at different rates, in different locations. There are a lot of reasons for this, but some of the big ones might be geography and resources. The more remote a park, the harder it is to get a repair team to it---and the less-resourced a park, the lower the likelihood they have on-site repair teams, or are prioritised by the repair teams that can be dispatched.\n\nThinking about this, look at the locations of the following parks. Suppose that each one has an outage in their induction loop: which ones would you expect to be fixed first, and why? Research the parks, and rank them on a scale of 1 to 5 (1 being highest, and 5 being lowest) of which would be fixed quickest.\n\n| Park               | Priority (1-5) | Reason |\n|--------------------|----------------|--------|\n| Acadia NP          |                |        |\n| Lassen Volcanic NP |                |        |\n| Saguaro NP         |                |        |\n| Yosemite NP        |                |        |\n| Mammoth Cave NP    |                |        |\n:::\n",
    "supporting": [
      "np-data_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}